#!/usr/bin/env python3
"""
PerfAgent é›†æˆæ‰§è¡Œè„šæœ¬
æ¨¡ä»¿ SE/basic_run.py çš„ç»“æ„ï¼Œåœ¨ SE æ¡†æ¶ä¸­é©±åŠ¨ perfagent çš„å•/å¤šå®ä¾‹æ€§èƒ½ä¼˜åŒ–ã€‚
"""

import argparse
import json
import math
import os
import subprocess
import sys
import tempfile
from datetime import datetime
from pathlib import Path

import yaml

# æ·»åŠ SEç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥SEæ—¥å¿—ç³»ç»Ÿ
from core.utils.se_logger import get_se_logger, setup_se_logging
from core.utils.traj_extractor import TrajExtractor
from core.utils.traj_pool_manager import TrajPoolManager
from core.utils.trajectory_processor import TrajectoryProcessor

# å¯¼å…¥operatorç³»ç»Ÿ
from operators import create_operator


def _prepare_initial_code_dir(
    initial_code_dir: Path, input_labels: list[str], traj_pool_manager: TrajPoolManager, logger
) -> Path | None:
    """
    å‡†å¤‡åˆå§‹ä»£ç ç›®å½•ï¼šä»è½¨è¿¹æ± ä¸­æå–æŒ‡å®šæ ‡ç­¾çš„ä»£ç ï¼Œå†™å…¥åˆ° initial_code_dirã€‚
    ç”¨äºæ”¯æŒåŸºäºå·²æœ‰è½¨è¿¹ç»§ç»­ä¼˜åŒ–çš„åœºæ™¯ã€‚
    """
    try:
        initial_code_dir.mkdir(parents=True, exist_ok=True)
        written_instances: set[str] = set()

        pool_data = traj_pool_manager.get_all_trajectories() or {}
        for label in input_labels:
            found_inst = None
            found_entry = None
            for inst_name, entry in pool_data.items():
                if not isinstance(entry, dict):
                    continue
                if label in entry and isinstance(entry[label], dict):
                    found_inst = str(inst_name)
                    found_entry = entry[label]
                    break
            if not found_inst or not isinstance(found_entry, dict):
                logger.warning(f"åˆå§‹ä»£ç å‡†å¤‡ï¼šæœªæ‰¾åˆ°è½¨è¿¹ {label}")
                continue
            code = (
                found_entry.get("content")
                or ((found_entry.get("summary") or {}).get("final_solution") or {}).get("code")
                or ""
            )
            if not code:
                logger.warning(f"åˆå§‹ä»£ç å‡†å¤‡ï¼šè½¨è¿¹ {label} ç¼ºå°‘ä»£ç å†…å®¹")
                continue
            if found_inst in written_instances:
                logger.info(f"åˆå§‹ä»£ç å‡†å¤‡ï¼šå®ä¾‹ {found_inst} å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤æ ‡ç­¾ {label}")
                continue
            file_path = initial_code_dir / f"{found_inst}.py"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(code)
            written_instances.add(found_inst)
        if not written_instances:
            logger.warning("åˆå§‹ä»£ç å‡†å¤‡ï¼šæ²¡æœ‰ä»»ä½•ä»£ç æ–‡ä»¶è¢«å†™å…¥")
            return None
        return initial_code_dir
    except Exception as e:
        logger.error(f"åˆå§‹ä»£ç å‡†å¤‡å¤±è´¥: {e}")
        return None


def _execute_operator_step(
    step: dict, se_config: dict, traj_pool_manager: TrajPoolManager, workspace_dir: str, logger
) -> dict:
    """
    æ‰§è¡Œå•ä¸ªç®—å­æ­¥éª¤ã€‚
    æ ¹æ® operator_name åˆ›å»ºç®—å­å®ä¾‹å¹¶è°ƒç”¨å…¶ run æ–¹æ³•ã€‚
    """
    operator_name = step.get("operator")
    if not operator_name:
        logger.error("ç®—å­æ­¥éª¤ç¼ºå°‘ operator å­—æ®µ")
        return {}

    # å°†é€‰æ‹©æ¨¡å¼æ³¨å…¥ç®—å­é…ç½®ï¼ˆç®—å­å†…éƒ¨ä¼˜å…ˆä½¿ç”¨ step['selection_mode']ï¼Œå…¶æ¬¡ä½¿ç”¨ config['operator_selection_mode']ï¼‰
    op_cfg = dict(se_config) if isinstance(se_config, dict) else {}
    try:
        if isinstance(step, dict) and step.get("selection_mode"):
            op_cfg["operator_selection_mode"] = step.get("selection_mode")
    except Exception:
        pass
    operator = create_operator(operator_name, op_cfg)
    if not operator:
        logger.error(f"æ— æ³•åˆ›å»ºç®—å­å®ä¾‹: {operator_name}")
        return {}

    result = {}
    try:
        result = operator.run(step, traj_pool_manager, workspace_dir)
    except Exception as e:
        logger.error(f"ç®—å­æ‰§è¡Œå¤±è´¥: {operator_name}, {e}")
        return {}

    if isinstance(result.get("initial_code_dir"), str):
        p = Path(result["initial_code_dir"]) if result.get("initial_code_dir") else None
        if p and p.exists():
            logger.info(f"ç®—å­è¿”å›åˆå§‹ä»£ç ç›®å½•: {p}")
        gen_cnt = result.get("generated_count")
        try:
            if gen_cnt is not None:
                logger.info(f"ç®—å­ç”Ÿæˆåˆå§‹ä»£ç æ•°é‡: {int(gen_cnt)}")
        except Exception:
            pass

    # å†å²å…¼å®¹ï¼šä¸å†æ”¯æŒ add_to_poolï¼Œç®—å­å¿…é¡»è¿”å› initial_code_dir
    return result


def _summarize_iteration_to_pool(
    iteration_dir: Path,
    iteration_index: int,
    traj_pool_manager: TrajPoolManager,
    se_config: dict,
    logger,
    label_prefix: str | None = None,
    source_labels: list[str] | None = None,
    source_labels_map: dict[str, list[str]] | None = None,
    operator_name: str | None = None,
) -> None:
    """
    å°†ä¸€æ¬¡è¿­ä»£ç”Ÿæˆçš„è½¨è¿¹æ•°æ®ï¼ˆ.tra æ–‡ä»¶ç­‰ï¼‰æå–å¹¶æ±‡æ€»åˆ°è½¨è¿¹æ± ä¸­ã€‚
    åŒ…å«æå–å®ä¾‹æ•°æ®ã€æ ¼å¼åŒ–è½¨è¿¹æ¡ç›®ã€å¹¶è°ƒç”¨ traj_pool_manager è¿›è¡ŒæŒä¹…åŒ–ã€‚
    """
    try:
        extractor = TrajExtractor()
        # åŒ…å«æ€§èƒ½æŒ‡æ ‡
        extracted = extractor.extract_instance_data(iteration_dir, include_metrics=True)
        if not extracted:
            logger.warning("æœ¬è¿­ä»£æ²¡æœ‰æœ‰æ•ˆçš„å®ä¾‹æ•°æ®ç”¨äºè½¨è¿¹æ± æ€»ç»“")
            return
        trajectories_to_process = []
        for item in extracted:
            try:
                instance_name, problem_description, tra_content, patch_content, perf_metrics = item
            except Exception:
                # å…¼å®¹ä¸å« metrics çš„æ—§æ ¼å¼
                instance_name, problem_description, tra_content, patch_content = item
                perf_metrics = None
            label = str(label_prefix) if label_prefix else f"iter{iteration_index}"
            per_inst_src = None
            try:
                if source_labels_map and isinstance(source_labels_map, dict):
                    per_inst_src = source_labels_map.get(str(instance_name))
            except Exception:
                per_inst_src = None
            trajectories_to_process.append(
                {
                    "label": label,
                    "instance_name": instance_name,
                    "problem_description": problem_description,
                    "trajectory_content": tra_content,
                    "patch_content": patch_content,
                    "iteration": iteration_index,
                    "performance": (perf_metrics or {}).get("final_performance"),
                    "source_dir": str(iteration_dir / instance_name),
                    "source_entry_labels": list(per_inst_src or []),
                    "operator_name": str(operator_name) if operator_name is not None else None,
                }
            )
        traj_pool_manager.summarize_and_add_trajectories(
            trajectories_to_process, num_workers=se_config.get("num_workers")
        )
        pool_stats = traj_pool_manager.get_pool_stats()
        logger.info(f"è½¨è¿¹æ± æ›´æ–°: {pool_stats['total_trajectories']}æ¡è½¨è¿¹")
    except Exception as pool_error:
        logger.error(f"è¿­ä»£è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {pool_error}")


def write_iteration_preds(base_dir: Path, logger) -> Path | None:
    """
    èšåˆå½“å‰è¿­ä»£å„å®ä¾‹çš„ç»“æœï¼Œç”Ÿæˆ preds.jsonã€‚

    - passedï¼šç›´æ¥ä¾æ® final_performance æ˜¯å¦ä¸º infï¼ˆæˆ–å­—ç¬¦ä¸²è¡¨ç¤ºçš„æ— ç©·ï¼‰åˆ¤æ–­ã€‚
    - runtimeï¼šè¾“å‡ºæœ€ç»ˆæ€§èƒ½å€¼ï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œå¦åˆ™å›é€€åˆ°åˆå§‹è¯„ä¼°çš„ä¿®å‰ªå‡å€¼ã€‚
    - codeï¼šä¼˜å…ˆä½¿ç”¨ optimized_codeï¼Œå›é€€åˆ° initial_codeã€‚

    è¿”å›ç”Ÿæˆçš„ preds.json è·¯å¾„ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    preds = {}
    try:
        for inst_dir in base_dir.iterdir():
            if not inst_dir.is_dir():
                continue
            res_file = inst_dir / "result.json"
            if not res_file.exists():
                continue
            try:
                with open(res_file, encoding="utf-8") as f:
                    data = json.load(f)
            except Exception:
                continue

            instance_id = data.get("instance_id", inst_dir.name)
            code = data.get("optimized_code", "")

            # è¯»å–æœ€ç»ˆæ€§èƒ½å€¼å¹¶ç”¨äº passed åˆ¤æ–­
            final_perf = data.get("final_performance")

            # runtimeï¼šä¼˜å…ˆ final_performanceï¼Œå¦åˆ™ initial trimmed_mean
            runtime = final_perf

            # passedï¼šfinal_performance ä¸º inf åˆ™ Falseï¼Œå¦åˆ™ True
            passed = not math.isinf(float(final_perf)) if final_perf is not None else False
            preds[str(instance_id)] = {
                "code": code,
                "passed": passed,
                "runtime": runtime,
            }

        preds_path = base_dir / "preds.json"
        with open(preds_path, "w", encoding="utf-8") as pf:
            json.dump(preds, pf, indent=2, ensure_ascii=False)
        print(f"ğŸ“ å·²ç”Ÿæˆ preds.json: {preds_path}")
        logger.info(f"å·²ç”Ÿæˆ preds.json: {preds_path}")
        return preds_path
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ preds.json å¤±è´¥: {e}")
        return None


def aggregate_all_iterations_preds(root_output_dir: Path, logger) -> Path | None:
    """
    æ±‡æ€»æ‰€æœ‰ iteration_* ç›®å½•ä¸‹çš„ preds.jsonï¼Œæ·»åŠ è¿­ä»£å·å¹¶å†™å…¥è¿è¡Œæ ¹ç›®å½•çš„ preds.jsonã€‚

    å˜æ›´ï¼šä¸å†è¿‡æ»¤æœªé€šè¿‡é¡¹ã€‚å¯¹äºæœªé€šè¿‡çš„å®ä¾‹ï¼Œå…¶ code å­—æ®µæ˜ç¡®è®¾ä¸ºç©ºå­—ç¬¦ä¸²""ï¼Œä»¥é¿å…åç»­è¾“å‡ºç¼ºå¤±ã€‚

    è¾“å‡ºç»“æ„ç¤ºä¾‹ï¼š
    {
      "inst1": [
        {"iteration": 1, "code": "...", "runtime": 1.23},
        {"iteration": 2, "code": "...", "runtime": 1.11}
      ],
      "inst2": [
        {"iteration": 2, "code": "", "runtime": "Infinity"}
      ]
    }
    """
    aggregated: dict[str, list[dict]] = {}
    try:
        for iter_dir in sorted(root_output_dir.glob("iteration_*")):
            if not iter_dir.is_dir():
                continue
            # è§£æè¿­ä»£å·
            try:
                iter_num = int(iter_dir.name.split("_")[-1])
            except Exception:
                iter_num = None

            preds_file = iter_dir / "preds.json"
            if not preds_file.exists():
                continue
            try:
                with open(preds_file, encoding="utf-8") as pf:
                    preds = json.load(pf)
            except Exception:
                continue

            for instance_id, info in preds.items():
                try:
                    passed = bool(info.get("passed", False))
                    # æœªé€šè¿‡çš„å®ä¾‹ï¼Œcode æ˜ç¡®ç½®ä¸ºç©ºå­—ç¬¦ä¸²
                    code = info.get("code", "") if passed else ""
                    runtime = info.get("runtime")
                    entry = {"iteration": iter_num, "code": code, "runtime": runtime}
                    aggregated.setdefault(str(instance_id), []).append(entry)
                except Exception:
                    continue

        agg_path = root_output_dir / "preds.json"
        with open(agg_path, "w", encoding="utf-8") as f:
            json.dump(aggregated, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ æ±‡æ€» preds.json: {agg_path}")
        logger.info(f"æ±‡æ€» preds.json: {agg_path}")
        return agg_path
    except Exception as e:
        logger.warning(f"æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None


def write_final_json_from_preds(aggregated_preds_path: Path, root_output_dir: Path, logger) -> Path | None:
    """
    ä»è¿è¡Œæ ¹ç›®å½•çš„ preds.jsonï¼ˆæ±‡æ€»ï¼‰é€‰æ‹©æ¯ä¸ªå®ä¾‹ runtime æœ€å°çš„è§£ï¼Œå†™å…¥ final.jsonã€‚

    æ–‡ä»¶ç»“æ„ï¼š
    {
      "instance_name": "code"
    }
    """
    try:
        with open(aggregated_preds_path, encoding="utf-8") as f:
            aggregated = json.load(f)
    except Exception as e:
        logger.warning(f"è¯»å–æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None

    def to_float(rt):
        try:
            if rt is None:
                return float("inf")
            if isinstance(rt, (int, float)):
                return float(rt)
            if isinstance(rt, str):
                lowered = rt.strip().lower()
                if lowered in ("inf", "infinity", "nan"):
                    return float("inf")
                return float(rt)
            return float("inf")
        except Exception:
            return float("inf")

    final_map: dict[str, str] = {}
    try:
        # å…ˆæ ¹æ®æœ€å° runtime é€‰æ‹©æœ€ä½³è§£ï¼›è‹¥å‡æœªé€šè¿‡ï¼ˆruntime ä¸º infï¼‰ï¼Œcode ä¼šæ˜¯ç©ºå­—ç¬¦ä¸²
        for instance_id, entries in aggregated.items():
            if not isinstance(entries, list) or not entries:
                continue
            try:
                best = min(entries, key=lambda e: to_float(e.get("runtime")))
            except Exception:
                continue
            final_map[str(instance_id)] = best.get("code", "") or ""

        # æ³¨ï¼šä¸å†è¿›è¡Œâ€œè¡¥é½ç©ºå­—ç¬¦ä¸²â€ï¼Œfinal.json ä»…ä¾æ®æ±‡æ€» preds.json çš„æœ€å° runtime é€‰æ‹©ç»“æœã€‚

        final_path = root_output_dir / "final.json"
        with open(final_path, "w", encoding="utf-8") as f:
            json.dump(final_map, f, indent=2, ensure_ascii=False)
        print(f"ğŸ ç”Ÿæˆ final.json: {final_path}")
        logger.info(f"ç”Ÿæˆ final.json: {final_path}")
        return final_path
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ final.json å¤±è´¥: {e}")
        return None


def create_temp_perf_config(
    base_config_path: str | None,
    se_model_cfg: dict,
    logger,
    extra_overrides: dict | None = None,
) -> Path | None:
    """åŸºäºåŸºç¡€é…ç½®ç”Ÿæˆä¸€ä¸ªä¸´æ—¶ PerfAgent é…ç½®æ–‡ä»¶ï¼Œå¹¶æŒ‰éœ€è¦†ç›–å­—æ®µã€‚

    - è¦†ç›–æ¨¡å‹ç›¸å…³å­—æ®µï¼ˆæ¥è‡ª SE ä¸»æ¨¡å‹è®¾ç½®ï¼‰
    - è¦†ç›–é¡¶å±‚æ§åˆ¶å­—æ®µï¼ˆç›®å‰æ”¯æŒ max_iterationsï¼‰ï¼Œç”¨äºä¸ SE é…ç½®å¯¹é½

    è¿”å›ä¸´æ—¶é…ç½®æ–‡ä»¶è·¯å¾„ï¼›è‹¥å¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    try:
        perf_cfg = {}
        if base_config_path:
            with open(base_config_path, encoding="utf-8") as f:
                perf_cfg = yaml.safe_load(f) or {}

        # ä»…è¦†ç›– PerfAgent æ”¯æŒçš„æ¨¡å‹å­—æ®µ
        allowed_keys = [
            "name",
            "api_base",
            "api_key",
            "max_input_tokens",
            "max_output_tokens",
            "temperature",
        ]
        override_model = {
            k: v
            for k, v in (se_model_cfg or {}).items()
            if k in allowed_keys and v is not None and (str(v).strip() != "")
        }

        perf_cfg.setdefault("model", {})
        perf_cfg["model"].update(override_model)

        # é¡¶å±‚è¦†ç›–ï¼šæ”¯æŒä» SE é…ç½®ä¼ å…¥çš„ max_iterations
        if extra_overrides:
            if "max_iterations" in extra_overrides:
                mi = extra_overrides.get("max_iterations")
                if mi is not None and str(mi).strip() != "":
                    try:
                        perf_cfg["max_iterations"] = int(mi)
                    except Exception:
                        # è‹¥æ— æ³•è½¬æ¢ä¸ºæ•´æ•°ï¼Œä»æŒ‰åŸå€¼å†™å…¥ï¼Œé¿å…ä¸­æ–­
                        perf_cfg["max_iterations"] = mi

        # ç”Ÿæˆä¸´æ—¶ YAML æ–‡ä»¶
        tmp = tempfile.NamedTemporaryFile("w", suffix=".yaml", delete=False)
        yaml.safe_dump(perf_cfg, tmp, sort_keys=False, allow_unicode=True)
        tmp_path = Path(tmp.name)
        tmp.close()

        print(f"ğŸ§© å·²ç”Ÿæˆä¸´æ—¶PerfAgenté…ç½®: {tmp_path}")
        logger.info(f"ä¸´æ—¶PerfAgenté…ç½®(æ¨¡å‹è¦†ç›–): {json.dumps(override_model, ensure_ascii=False)}")
        if extra_overrides and "max_iterations" in extra_overrides:
            logger.info(f"ä¸´æ—¶PerfAgenté…ç½®(è¿­ä»£è¦†ç›–): max_iterations={perf_cfg.get('max_iterations')}")
        return tmp_path
    except Exception as e_cfg:
        logger.warning(f"ç”Ÿæˆä¸´æ—¶PerfAgenté…ç½®å¤±è´¥: {e_cfg}")
        return None


def call_perfagent(iteration_params, logger, dry_run=False):
    """
    ç›´æ¥è°ƒç”¨ perfagent.run_batch çš„æ‰¹é‡æ‰§è¡Œæ¥å£ï¼Œè¿è¡Œæœ¬æ¬¡è¿­ä»£çš„å®ä¾‹ä¼˜åŒ–ã€‚

    Args:
        iteration_params: åŒ…å«é…ç½®è·¯å¾„ã€å®ä¾‹ç›®å½•ã€è¾“å‡ºç›®å½•ç­‰å‚æ•°çš„å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨
        dry_run: è‹¥ä¸º Trueï¼Œä»…æ‰“å°å‘½ä»¤é¢„è§ˆè€Œä¸å®é™…æ‰§è¡Œï¼ˆç”¨äºæ¼”ç¤ºæ¨¡å¼ï¼‰

    Returns:
        dict: æ‰§è¡Œç»“æœï¼ŒåŒ…å« status, returncode ç­‰
    """
    base_config_path = iteration_params.get("perf_base_config")

    try:
        # åŸºç¡€é…ç½® + SE ä¸»æ¨¡å‹é…ç½®è¦†ç›– => ç”Ÿæˆä¸´æ—¶ PerfAgent é…ç½®
        logger.debug(f"ä½¿ç”¨PerfAgentåŸºç¡€é…ç½®: {base_config_path}")

        if dry_run:
            # åœ¨æ¼”ç¤ºæ¨¡å¼ä¸‹ä¹Ÿæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„å‘½ä»¤ï¼ˆåŒ…å«å…³é”®å‚æ•°ï¼‰ï¼Œä¾¿äºæ ¸å¯¹
            base_dir = Path(iteration_params["output_dir"]).resolve()
            base_dir.mkdir(parents=True, exist_ok=True)
            se_model_cfg = iteration_params.get("model") or {}
            temp_config_path = (
                create_temp_perf_config(
                    base_config_path,
                    se_model_cfg,
                    logger,
                    extra_overrides={
                        "max_iterations": iteration_params.get("max_iterations"),
                    },
                )
                or base_config_path
            )
            cmd_preview = [sys.executable, "-m", "perfagent.run_batch"]
            if temp_config_path:
                cmd_preview.extend(["--config", str(temp_config_path)])
            cmd_preview.extend(
                [
                    "--instances-dir",
                    str(iteration_params.get("instances_dir")),
                    "--base-dir",
                    str(base_dir),
                    "--max-workers",
                    str(iteration_params.get("num_workers", 1)),
                ]
            )
            operator_params = iteration_params.get("operator_params", {}) or {}
            icd = operator_params.get("initial_code_dir")
            itd = operator_params.get("instance_templates_dir")
            if icd:
                cmd_preview.extend(["--initial-code-dir", str(icd)])
            if itd:
                cmd_preview.extend(["--instance-templates-dir", str(itd)])
            print(f"ğŸš€ [DEMO] PerfAgentå‘½ä»¤é¢„è§ˆ: {' '.join(cmd_preview)}")
            logger.warning("æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡PerfAgentå®é™…æ‰§è¡Œ")
            return {"status": "skipped", "reason": "dry_run", "preview_cmd": " ".join(cmd_preview)}

        # ç›®æ ‡è·¯å¾„å’Œå‘½ä»¤ï¼ˆæ‰¹é‡æ‰§è¡Œè„šæœ¬ï¼‰
        se_root = Path(__file__).parent
        project_root = se_root.parent

        # é€‰æ‹©å®ä¾‹ç›®å½•
        instances_dir = iteration_params.get("instances_dir")

        # åŸºç¡€ç›®å½•ï¼šä½¿ç”¨å½“å‰è¿­ä»£çš„è¾“å‡ºç›®å½•ï¼Œè®©æ¯ä¸ªå®ä¾‹åœ¨å…¶å­ç›®å½•ä¸‹ç”Ÿæˆæ—¥å¿—ä¸è½¨è¿¹
        base_dir = Path(iteration_params["output_dir"]).resolve()
        base_dir.mkdir(parents=True, exist_ok=True)

        # å°è£…ï¼šç”Ÿæˆä¸´æ—¶é…ç½®ï¼ˆåŒ…å«æ¨¡å‹è¦†ç›–ï¼‰ï¼›å¤±è´¥åˆ™å›é€€åˆ°åŸºç¡€é…ç½®
        se_model_cfg = iteration_params.get("model") or {}
        if base_config_path:
            print(f"ğŸ“‹ ä½¿ç”¨åŸºç¡€é…ç½®æ–‡ä»¶: {base_config_path}")
        temp_config_path = (
            create_temp_perf_config(
                base_config_path,
                se_model_cfg,
                logger,
                extra_overrides={
                    "max_iterations": iteration_params.get("max_iterations"),
                },
            )
            or base_config_path
        )

        # ä¼˜å…ˆä½¿ç”¨åŸºç¡€é…ç½®ï¼›operator ä»…è¿”å› initial_code_dirï¼ˆä¸å†ä½¿ç”¨ instance_templates_dirï¼‰
        # ç»„è£…å‘½ä»¤ï¼šå…ˆæ”¾ --configï¼ˆè‹¥æœ‰ï¼‰ï¼Œå†ä¾æ¬¡åŠ å…¥å…¶ä»–å‚æ•°ï¼Œé¿å…è§£æå†²çª
        cmd = [sys.executable, "-m", "perfagent.run_batch"]
        if temp_config_path:
            cmd.extend(["--config", str(temp_config_path)])
        cmd.extend(
            [
                "--instances-dir",
                str(instances_dir),
                "--base-dir",
                str(base_dir),
                "--max-workers",
                str(iteration_params.get("num_workers", 1)),
            ]
        )

        # ä¼ é€’ç®—å­è¾“å‡ºå‚æ•°
        operator_params = iteration_params.get("operator_params", {}) or {}
        icd = operator_params.get("initial_code_dir")
        if icd:
            cmd.extend(["--initial-code-dir", str(icd)])
        itd = operator_params.get("instance_templates_dir")
        if itd:
            cmd.extend(["--instance-templates-dir", str(itd)])

        print(f"ğŸš€ æ‰§è¡ŒPerfAgentæ‰¹é‡å‘½ä»¤: {' '.join(cmd)}")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {project_root}")
        print("=" * 60)

        result = subprocess.run(cmd, cwd=str(project_root), text=True)

        print("=" * 60)
        if result.returncode == 0:
            logger.info("PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡ŒæˆåŠŸ")
            print("âœ… PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡ŒæˆåŠŸ")

            preds_path = write_iteration_preds(base_dir, logger)
            return {
                "status": "success",
                "summary": "success",
                "base_dir": str(base_dir),
                "preds_file": str(preds_path) if preds_path else None,
            }
        else:
            logger.error(f"PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"âŒ PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return {"status": "failed", "returncode": result.returncode}

    except Exception as e:
        logger.error(f"è°ƒç”¨PerfAgentæ—¶å‡ºé”™: {e}", exc_info=True)
        return {"status": "error", "exception": str(e)}
    finally:
        # æ— ä¸´æ—¶é…ç½®éœ€è¦æ¸…ç†
        pass


def main():
    """
    ä¸»å‡½æ•°ï¼šç­–ç•¥é©±åŠ¨çš„ PerfAgent å¤šè¿­ä»£æ‰§è¡Œã€‚
    è§£æå‘½ä»¤è¡Œå‚æ•°å’Œ SE é…ç½®æ–‡ä»¶ï¼ŒæŒ‰æ­¥éª¤æ‰§è¡Œé…ç½®ä¸­çš„ç®—å­å’Œ PerfAgent è¿­ä»£ã€‚
    """

    parser = argparse.ArgumentParser(description="SE æ¡†æ¶ PerfAgent å¤šè¿­ä»£æ‰§è¡Œè„šæœ¬")
    parser.add_argument("--config", default="SE/configs/se_configs/dpsk.yaml", help="SE é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--mode", choices=["demo", "execute"], default="execute", help="è¿è¡Œæ¨¡å¼: demo=æ¼”ç¤ºæ¨¡å¼, execute=ç›´æ¥æ‰§è¡Œ"
    )
    args = parser.parse_args()

    print("=== SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œ ===")
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")

    try:
        # è¯»å– SE é…ç½®æ–‡ä»¶
        with open(args.config, encoding="utf-8") as f:
            se_config = yaml.safe_load(f)

        # ç”Ÿæˆ timestamp å¹¶æ›¿æ¢è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = se_config["output_dir"].replace("{timestamp}", timestamp)

        # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
        log_file = setup_se_logging(output_dir)
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")

        logger = get_se_logger("perf_run", emoji="âš¡")
        logger.info("SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œå¯åŠ¨")
        logger.debug(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        logger.info(f"ç”Ÿæˆtimestamp: {timestamp}")
        logger.info(f"å®é™…è¾“å‡ºç›®å½•: {output_dir}")

        # è®¾ç½®å…¨å±€ token ç»Ÿè®¡æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆæŒ‰è¿è¡Œè¾“å‡ºç›®å½•éš”ç¦»ï¼‰
        os.environ["SE_TOKEN_LOG_PATH"] = str(Path(output_dir) / "token_usage.jsonl")

        # åˆå§‹åŒ–è½¨è¿¹æ± ç®¡ç†å™¨
        traj_pool_path = os.path.join(output_dir, "traj.pool")

        # åˆ›å»ºLLMå®¢æˆ·ç«¯ç”¨äºè½¨è¿¹æ€»ç»“
        llm_client = None
        try:
            from core.utils.llm_client import LLMClient

            # ä½¿ç”¨operator_modelsé…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¸»æ¨¡å‹é…ç½®
            llm_client = LLMClient.from_se_config(se_config, use_operator_model=True)
            logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {llm_client.config['name']}")
        except Exception as e:
            logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ€»ç»“: {e}")

        # å°† se_config ä¸­çš„å¹¶å‘æ§åˆ¶ä¼ å…¥ TrajPoolManager
        traj_pool_manager = TrajPoolManager(traj_pool_path, llm_client, num_workers=se_config.get("num_workers"))
        traj_pool_manager.initialize_pool()
        logger.info(f"è½¨è¿¹æ± åˆå§‹åŒ–: {traj_pool_path}")
        print(f"ğŸŠ è½¨è¿¹æ± : {traj_pool_path}")

        print("\nğŸ“Š é…ç½®æ¦‚è§ˆ:")
        print(f"  åŸºç¡€é…ç½®: {se_config['base_config']}")
        print(f"  æ¨¡å‹: {se_config['model']['name']}")
        print(f"  å®ä¾‹ç›®å½•: {se_config['instances']['instances_dir']}")
        print(f"  è¾“å‡ºç›®å½•: {output_dir}")

        # ============ å¼€å§‹ PerfAgent å¤šè¿­ä»£æ‰§è¡Œ ============

        iterations = se_config.get("strategy", {}).get("iterations", [])
        print(f"  è¿­ä»£æ¬¡æ•°: {len(iterations)}")

        try:
            existing = [int(p.name.split("_")[-1]) for p in Path(output_dir).glob("iteration_*") if p.is_dir()]
            next_iteration_index = (max(existing) if existing else 0) + 1
        except Exception:
            next_iteration_index = 1

        for step_idx, iteration in enumerate(iterations, 1):
            operator_name = iteration.get("operator")
            is_filter_operator = str(operator_name) in ("filter", "filter_trajectories")

            def build_common_params(out_dir: str) -> dict:
                return {
                    "perf_base_config": iteration.get("perf_base_config"),
                    "operator": operator_name,
                    "model": se_config.get("model", {}),
                    "instances_dir": se_config.get("instances", {}).get("instances_dir", ""),
                    "output_dir": out_dir,
                    "max_iterations": se_config.get("max_iterations", 10),
                    "num_workers": se_config.get("num_workers", 1),
                }

            # ============ æ‰§è¡Œç®—å­ ============
            if operator_name == "plan":
                print("ğŸ”§ æ‰§è¡Œç®—å­: plan (å±•å¼€ä¸ºå¤šæ¬¡è¿­ä»£)")
                step = {
                    "operator": "plan",
                    "num": iteration.get("num"),
                    "trajectory_labels": iteration.get("trajectory_labels"),
                }
                op_result = _execute_operator_step(step, se_config, traj_pool_manager, output_dir, logger)
                plans = op_result.get("plans") or []
                for plan in plans:
                    label = str(plan.get("label")) if plan.get("label") else None
                    per_inst = plan.get("per_instance_requirements") or {}

                    iteration_output_dir = f"{output_dir}/iteration_{next_iteration_index}"
                    system_prompt_dir = Path(iteration_output_dir) / "system_prompt"
                    try:
                        system_prompt_dir.mkdir(parents=True, exist_ok=True)
                        for inst_name, req in per_inst.items():
                            try:
                                file_path = system_prompt_dir / f"{inst_name}.yaml"
                                data = {"prompts": {"additional_requirements": str(req)}}
                                with open(file_path, "w", encoding="utf-8") as f:
                                    yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)
                            except Exception:
                                pass
                        instance_templates_dir_for_run = str(system_prompt_dir)
                    except Exception:
                        instance_templates_dir_for_run = None

                    iteration_params = build_common_params(iteration_output_dir)
                    if instance_templates_dir_for_run:
                        iteration_params["operator_params"] = {"instance_templates_dir": instance_templates_dir_for_run}

                    print(f"\n=== ç¬¬{next_iteration_index}æ¬¡PerfAgentè¿­ä»£è°ƒç”¨ ===")
                    print(f"ä½¿ç”¨é…ç½®: {iteration.get('perf_base_config', 'None')}")
                    print(f"ç®—å­: plan -> {label}")
                    print(f"è¾“å‡ºç›®å½•: {iteration_output_dir}")

                    if args.mode == "execute":
                        logger.info(f"ç›´æ¥æ‰§è¡Œæ¨¡å¼ï¼šè¿­ä»£ {next_iteration_index}")
                        result = call_perfagent(iteration_params, logger, dry_run=False)
                        print(f"æ‰§è¡Œç»“æœ: {result['status']}")
                        if result.get("status") == "success":
                            try:
                                processor = TrajectoryProcessor()
                                iteration_dir = Path(iteration_output_dir)
                                tra_stats = processor.process_iteration_directory(iteration_dir)

                                if tra_stats and tra_stats.get("total_tra_files", 0) > 0:
                                    _summarize_iteration_to_pool(
                                        iteration_dir,
                                        next_iteration_index,
                                        traj_pool_manager,
                                        se_config,
                                        logger,
                                        label_prefix=label,
                                        source_labels=[],
                                        source_labels_map=None,
                                        operator_name=operator_name,
                                    )
                                else:
                                    logger.warning(f"è¿­ä»£ {next_iteration_index} æœªç”Ÿæˆ.traæ–‡ä»¶")
                                    print("âš ï¸ æœªç”Ÿæˆ.traæ–‡ä»¶ï¼ˆå¯èƒ½æ²¡æœ‰æœ‰æ•ˆè½¨è¿¹ï¼‰")
                            except Exception as tra_error:
                                logger.error(f"è¿­ä»£ {next_iteration_index} ç”Ÿæˆ.traæ–‡ä»¶å¤±è´¥: {tra_error}")
                                print(f"âš ï¸ .traæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {tra_error}")
                    else:
                        logger.info(f"æ¼”ç¤ºæ¨¡å¼ï¼šè¿­ä»£ {next_iteration_index}")
                        result = call_perfagent(iteration_params, logger, dry_run=True)
                        print(f"æ¼”ç¤ºç»“æœ: {result['status']}")
                        print("ğŸ“ æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡.traæ–‡ä»¶ç”Ÿæˆä¸è½¨è¿¹æ± æ›´æ–°")

                    next_iteration_index += 1
                continue

            # é plan ç®—å­è·¯å¾„
            # å¸¸è§„ç®—å­æ‰§è¡Œé€»è¾‘ï¼š
            # 1. å‡†å¤‡ç®—å­è¾“å…¥ï¼ˆæºè½¨è¿¹æ ‡ç­¾ã€ç›®æ ‡æ ‡ç­¾ç­‰ï¼‰
            # 2. æ‰§è¡Œç®—å­ï¼ˆ_execute_operator_stepï¼‰
            # 3. è·å–ç®—å­è¾“å‡ºï¼ˆinitial_code_dir æˆ– instance_templates_dirï¼‰
            # 4. æ„å»º PerfAgent å‚æ•°å¹¶æ‰§è¡Œ
            initial_code_dir_for_run: str | None = None
            instance_templates_dir_for_run: str | None = None

            iteration_output_dir = f"{output_dir}/iteration_{next_iteration_index}"
            iteration_params = build_common_params(iteration_output_dir)

            if operator_name:
                print(f"ğŸ”§ æ‰§è¡Œç®—å­: {operator_name}")
                src_labels: list[str] = []
                if isinstance(iteration.get("source_trajectories"), list):
                    src_labels = [str(x) for x in iteration.get("source_trajectories")]
                elif iteration.get("source_trajectory"):
                    src_labels = [str(iteration.get("source_trajectory"))]

                outputs = []
                if iteration.get("trajectory_label"):
                    outputs = [{"label": str(iteration.get("trajectory_label"))}]

                strat_cfg = iteration.get("filter_strategy") or iteration.get("strategy") or {}

                step = {
                    "operator": operator_name,
                    "inputs": [{"label": l} for l in src_labels],
                    "outputs": outputs,
                    "strategy": strat_cfg,
                }
                op_result = _execute_operator_step(step, se_config, traj_pool_manager, iteration_output_dir, logger)
                if isinstance(op_result.get("initial_code_dir"), str):
                    initial_code_dir_for_run = op_result["initial_code_dir"]
                if isinstance(op_result.get("instance_templates_dir"), str):
                    instance_templates_dir_for_run = op_result["instance_templates_dir"]
                source_labels_map = op_result.get("source_entry_labels_per_instance") or {}
                if is_filter_operator:
                    logger.info("è¿‡æ»¤ç®—å­æ­¥éª¤ï¼Œæ‰§è¡Œåè·³è¿‡PerfAgent")
                    try:
                        ff = op_result.get("filtered_out_file")
                        pi = op_result.get("per_instance") or {}
                        kept_total = sum(len(v.get("kept_labels", [])) for v in pi.values())
                        deleted_total = sum(len(v.get("deleted_labels", [])) for v in pi.values())
                        if ff:
                            logger.info(f"è¿‡æ»¤è¾“å‡ºæ–‡ä»¶: {ff}")
                        logger.info(f"è¿‡æ»¤æ‘˜è¦: ä¿ç•™ {kept_total} æ¡, åˆ é™¤ {deleted_total} æ¡, å®ä¾‹ {len(pi)} ä¸ª")
                    except Exception:
                        pass
            else:
                print("ğŸ”„ æ— ç®—å­å¤„ç†")
                logger.debug("å½“å‰æ­¥éª¤æ— ç®—å­å¤„ç†")

            if initial_code_dir_for_run or instance_templates_dir_for_run:
                op_params = {}
                if initial_code_dir_for_run:
                    op_params["initial_code_dir"] = initial_code_dir_for_run
                if instance_templates_dir_for_run:
                    op_params["instance_templates_dir"] = instance_templates_dir_for_run
                iteration_params["operator_params"] = op_params

            logger.debug(f"è¿­ä»£å‚æ•°: {json.dumps(iteration_params, ensure_ascii=False)}")
            print(f"ä½¿ç”¨é…ç½®: {iteration.get('perf_base_config', 'None')}")
            print(f"ç®—å­: {iteration.get('operator', 'None')}")
            print(f"è¾“å‡ºç›®å½•: {iteration_output_dir}")

            # ============ æ‰§è¡Œ PerfAgent  ============

            if args.mode == "execute" and not is_filter_operator:
                logger.info(f"ç›´æ¥æ‰§è¡Œæ¨¡å¼ï¼šè¿­ä»£ {next_iteration_index}")
                result = call_perfagent(iteration_params, logger, dry_run=False)
                try:
                    logger.info(f"PerfAgentè¿”å›çŠ¶æ€: {result.get('status')}")
                except Exception:
                    pass
                print(f"æ‰§è¡Œç»“æœ: {result['status']}")

                # ============ å¤„ç† PerfAgent æ‰§è¡Œç»“æœ ============

                # æˆåŠŸåˆ™ç”Ÿæˆ.traå¹¶æ›´æ–° traj.pool
                # .tra ç›´æ¥ä½¿ç”¨ history ç”Ÿæˆ
                # traj.pool è½¨è¿¹æ€»ç»“é€šè¿‡ LLM Summary ç”Ÿæˆ
                if result.get("status") == "success":
                    try:
                        processor = TrajectoryProcessor()
                        iteration_dir = Path(iteration_output_dir)

                        # å¤„ç†å½“å‰è¿­ä»£ç›®å½•ä¸‹çš„æ‰€æœ‰å®ä¾‹ï¼Œç”Ÿæˆ .tra æ–‡ä»¶
                        tra_stats = processor.process_iteration_directory(iteration_dir)
                        if tra_stats and tra_stats.get("total_tra_files", 0) > 0:
                            prefix = iteration.get("trajectory_label")
                            # å°†ç”Ÿæˆçš„è½¨è¿¹æ±‡æ€»åˆ°å…¨å±€è½¨è¿¹æ± 
                            _summarize_iteration_to_pool(
                                iteration_dir,
                                next_iteration_index,
                                traj_pool_manager,
                                se_config,
                                logger,
                                label_prefix=prefix,
                                source_labels=src_labels,
                                source_labels_map=source_labels_map if isinstance(source_labels_map, dict) else None,
                                operator_name=operator_name,
                            )
                        else:
                            logger.warning(f"è¿­ä»£ {next_iteration_index} æœªç”Ÿæˆ.traæ–‡ä»¶")
                            print("âš ï¸ æœªç”Ÿæˆ.traæ–‡ä»¶ï¼ˆå¯èƒ½æ²¡æœ‰æœ‰æ•ˆè½¨è¿¹ï¼‰")
                    except Exception as tra_error:
                        logger.error(f"è¿­ä»£ {next_iteration_index} ç”Ÿæˆ.traæ–‡ä»¶å¤±è´¥: {tra_error}")
                        print(f"âš ï¸ .traæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {tra_error}")
                next_iteration_index += 1

            elif args.mode == "execute" and is_filter_operator:
                logger.info("è·³è¿‡PerfAgentæ‰§è¡Œï¼ˆè¿‡æ»¤ç®—å­ï¼‰")
                print("â­ï¸ è·³è¿‡PerfAgentæ‰§è¡Œï¼ˆfilterç®—å­ï¼‰")
            else:
                logger.info("æ¼”ç¤ºæ¨¡å¼ï¼šæœ¬æ­¥éª¤")
                if not is_filter_operator:
                    result = call_perfagent(iteration_params, logger, dry_run=True)
                    print(f"æ¼”ç¤ºç»“æœ: {result['status']}")
                    print("ğŸ“ æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡.traæ–‡ä»¶ç”Ÿæˆä¸è½¨è¿¹æ± æ›´æ–°")
                    next_iteration_index += 1
                else:
                    logger.info("æ¼”ç¤ºæ¨¡å¼ä¸‹è·³è¿‡PerfAgentï¼ˆè¿‡æ»¤ç®—å­ï¼‰")
                    print("â­ï¸ æ¼”ç¤ºæ¨¡å¼ä¸‹è·³è¿‡PerfAgentï¼ˆfilterç®—å­ï¼‰")

        logger.info("æ‰€æœ‰PerfAgentè¿­ä»£å‡†å¤‡å®Œæˆ")

        print("\nğŸ¯ æ‰§è¡Œæ€»ç»“:")
        try:
            parsed_iterations = len(se_config.get("strategy", {}).get("iterations", []))
        except Exception:
            parsed_iterations = 0
        print(f"  âœ… è§£æ{parsed_iterations}ä¸ªè¿­ä»£é…ç½®")
        print(f"  âœ… æ—¶é—´æˆ³: {timestamp}")
        print(f"  âœ… æ—¥å¿—æ–‡ä»¶: {log_file}")
        print(f"  ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        try:
            final_pool_stats = traj_pool_manager.get_pool_stats()
            print(f"  ğŸŠ è½¨è¿¹æ± : {final_pool_stats.get('total_trajectories', 0)}æ¡è½¨è¿¹")
            print(f"  ğŸŠ è½¨è¿¹æ± æ–‡ä»¶: {traj_pool_path}")
        except Exception:
            pass

        logger.info("SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œå®Œæˆ")

        # ===== ç»Ÿè®¡ token ä½¿ç”¨ =====
        print("\nğŸ“Š ç»Ÿè®¡ token ä½¿ç”¨:")

        # è¯»å–å¹¶æ±‡æ€»æœ¬æ¬¡è¿è¡Œçš„ token ä½¿ç”¨æƒ…å†µ
        token_log_file = Path(output_dir) / "token_usage.jsonl"
        total_prompt = 0
        total_completion = 0
        total = 0
        by_context: dict[str, dict[str, int]] = {}
        try:
            if token_log_file.exists():
                with open(token_log_file, encoding="utf-8") as f:
                    for line in f:
                        try:
                            rec = json.loads(line)
                        except Exception:
                            continue
                        pt = int(rec.get("prompt_tokens") or 0)
                        ct = int(rec.get("completion_tokens") or 0)
                        tt = int(rec.get("total_tokens") or (pt + ct))
                        ctx = str(rec.get("context") or "unknown")
                        total_prompt += pt
                        total_completion += ct
                        total += tt
                        agg = by_context.setdefault(ctx, {"prompt": 0, "completion": 0, "total": 0})
                        agg["prompt"] += pt
                        agg["completion"] += ct
                        agg["total"] += tt
        except Exception:
            pass

        print("\nğŸ“ˆ Token ä½¿ç”¨ç»Ÿè®¡:")
        print(f"  è¾“å…¥tokens: {total_prompt}")
        print(f"  è¾“å‡ºtokens: {total_completion}")
        print(f"  æ€»è®¡tokens: {total}")
        if by_context:
            print("  æŒ‰ä¸Šä¸‹æ–‡åˆ†ç±»:")
            for ctx, vals in by_context.items():
                print(f"    - {ctx}: prompt={vals['prompt']}, completion={vals['completion']}, total={vals['total']}")
        logger.info(
            json.dumps(
                {
                    "token_usage_total": {
                        "prompt": total_prompt,
                        "completion": total_completion,
                        "total": total,
                    },
                    "by_context": by_context,
                    "token_log_file": str(token_log_file),
                },
                ensure_ascii=False,
            )
        )

        # ================================== ä¾æ®è¾“å‡ºé€‰æ‹©æœ€ä½³ Solution ==================================

        logger.info("å¼€å§‹é€‰æ‹©æ¯ä¸ªä»»åŠ¡çš„æœ€ä¼˜è§£")
        try:
            # 1) æ±‡æ€»æ‰€æœ‰è¿­ä»£çš„ preds.json åˆ°è¿è¡Œæ ¹ç›®å½• preds.jsonï¼ˆå« iteration å­—æ®µï¼‰
            root_output_dir = Path(output_dir)
            agg_preds_path = aggregate_all_iterations_preds(root_output_dir, logger)

            # 2) ä»æ±‡æ€» preds.json é‡Œä¸ºæ¯ä¸ªå®ä¾‹é€‰å– runtime æœ€å°çš„è§£ï¼Œç”Ÿæˆ final.json
            if agg_preds_path and Path(agg_preds_path).exists():
                write_final_json_from_preds(Path(agg_preds_path), root_output_dir, logger)
            else:
                logger.warning("æœªæ‰¾åˆ°æ±‡æ€» preds.jsonï¼Œè·³è¿‡ final.json ç”Ÿæˆ")
        except Exception as sel_err:
            logger.warning(f"é€‰æ‹©æœ€ä¼˜è§£å¤±è´¥: {sel_err}")

    except Exception as e:
        if "logger" in locals():
            logger.error(f"è¿è¡Œå‡ºé”™: {e}", exc_info=True)
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
