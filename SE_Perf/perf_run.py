#!/usr/bin/env python3
"""
PerfAgent é›†æˆæ‰§è¡Œè„šæœ¬

åŠŸèƒ½ï¼š
    åœ¨ SE æ¡†æ¶ä¸­é©±åŠ¨ PerfAgent è¿›è¡Œå•æ¬¡æˆ–å¤šæ¬¡è¿­ä»£çš„æ€§èƒ½ä¼˜åŒ–ã€‚
    æ¨¡ä»¿ SE/basic_run.py çš„ç»“æ„ï¼Œæ”¯æŒç­–ç•¥é©±åŠ¨çš„æ‰§è¡Œæµç¨‹ã€‚
"""

import argparse
import json
import math
import os
import subprocess
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any

import yaml

# æ·»åŠ  SE æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥ SE æ ¸å¿ƒæ¨¡å—
from core.utils.local_memory_manager import LocalMemoryManager
from core.utils.se_logger import get_se_logger, setup_se_logging
from core.utils.traj_extractor import TrajExtractor
from core.utils.traj_pool_manager import TrajPoolManager
from core.utils.trajectory_processor import TrajectoryProcessor
from operators import create_operator

# --- è¾…åŠ©å‡½æ•° ---


def _execute_operator_step(
    step_config: dict[str, Any],
    se_config: dict[str, Any],
    traj_pool_manager: TrajPoolManager,
    workspace_dir: str,
    logger,
) -> dict[str, Any]:
    """
    æ‰§è¡Œå•ä¸ªç®—å­æ­¥éª¤ã€‚

    Args:
        step_config: ç®—å­æ­¥éª¤é…ç½®
        se_config: SE å…¨å±€é…ç½®
        traj_pool_manager: è½¨è¿¹æ± ç®¡ç†å™¨
        workspace_dir: å·¥ä½œç›®å½•
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        ç®—å­æ‰§è¡Œç»“æœå­—å…¸
    """
    operator_name = step_config.get("operator")
    if not operator_name:
        logger.error("ç®—å­æ‰§è¡Œé”™è¯¯ï¼šæ­¥éª¤é…ç½®ç¼ºå°‘ 'operator' å­—æ®µ")
        return {}

    # åˆå¹¶é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ step_config ä¸­çš„è®¾ç½®ï¼Œå…¶æ¬¡æ˜¯ se_config
    operator_config = dict(se_config) if isinstance(se_config, dict) else {}

    if step_config.get("selection_mode"):
        operator_config["operator_selection_mode"] = step_config.get("selection_mode")
    if step_config.get("prompt_config"):
        operator_config["prompt_config"] = step_config.get("prompt_config")

    operator_instance = create_operator(operator_name, operator_config)
    if not operator_instance:
        logger.error(f"æ— æ³•åˆ›å»ºç®—å­å®ä¾‹: {operator_name}")
        return {}

    result = {}
    try:
        result = operator_instance.run(step_config, traj_pool_manager, workspace_dir)
    except Exception as e:
        logger.error(f"ç®—å­ '{operator_name}' æ‰§è¡Œå¤±è´¥: {e}")
        return {}

    # è®°å½•ç»“æœæ—¥å¿—
    initial_code_path = result.get("initial_code_dir")
    if isinstance(initial_code_path, str) and initial_code_path:
        path_obj = Path(initial_code_path)
        if path_obj.exists():
            logger.info(f"ç®—å­è¿”å›åˆå§‹ä»£ç ç›®å½•: {path_obj}")

    generated_count = result.get("generated_count")
    if generated_count is not None:
        try:
            logger.info(f"ç®—å­ç”Ÿæˆåˆå§‹ä»£ç æ•°é‡: {int(generated_count)}")
        except (ValueError, TypeError):
            pass

    return result


def _summarize_iteration_to_pool(
    iteration_dir: Path,
    iteration_index: int,
    traj_pool_manager: TrajPoolManager,
    se_config: dict[str, Any],
    logger,
    label_prefix: str | None = None,
    source_labels_map: dict[str, list[str]] | None = None,
    operator_name: str | None = None,
) -> None:
    """
    æå–è¿­ä»£ç»“æœå¹¶æ›´æ–°åˆ°è½¨è¿¹æ± ã€‚
    """
    try:
        # æ›´æ–° prompt_config
        prompt_config = se_config.get("prompt_config")
        if isinstance(prompt_config, dict):
            traj_pool_manager.prompt_config = prompt_config

        extractor = TrajExtractor()
        # æå–å®ä¾‹æ•°æ®ï¼ŒåŒ…å«æ€§èƒ½æŒ‡æ ‡
        extracted_data = extractor.extract_instance_data(iteration_dir, include_metrics=True)

        if not extracted_data:
            logger.warning(f"è¿­ä»£ {iteration_index}ï¼šæ²¡æœ‰æœ‰æ•ˆçš„å®ä¾‹æ•°æ®ç”¨äºè½¨è¿¹æ± æ€»ç»“")
            return

        trajectories_to_process = []
        for item in extracted_data:
            # å…¼å®¹æ—§æ ¼å¼è§£åŒ…
            if len(item) == 5:
                instance_name, problem_desc, tra_content, patch_content, perf_metrics = item
            else:
                instance_name, problem_desc, tra_content, patch_content = item
                perf_metrics = None

            label = str(label_prefix) if label_prefix else f"iter{iteration_index}"

            # è·å–æºæ ‡ç­¾
            instance_source_labels = None
            if source_labels_map and isinstance(source_labels_map, dict):
                instance_source_labels = source_labels_map.get(str(instance_name))

            trajectories_to_process.append(
                {
                    "label": label,
                    "instance_name": instance_name,
                    "problem_description": problem_desc,
                    "trajectory_content": tra_content,
                    "patch_content": patch_content,
                    "iteration": iteration_index,
                    "performance": (perf_metrics or {}).get("performance"),
                    "source_dir": str(iteration_dir / instance_name),
                    "source_entry_labels": list(instance_source_labels or []),
                    "operator_name": str(operator_name) if operator_name else None,
                    "perf_metrics": perf_metrics,
                }
            )

        traj_pool_manager.summarize_and_add_trajectories(
            trajectories_to_process, num_workers=se_config.get("num_workers")
        )

        pool_stats = traj_pool_manager.get_pool_stats()
        logger.info(f"è½¨è¿¹æ± æ›´æ–°å®Œæ¯•: å½“å‰å…± {pool_stats.get('total_trajectories', 'unknown')} æ¡è½¨è¿¹")

    except Exception as e:
        logger.error(f"è¿­ä»£è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {e}")


def _extract_optimization_info(perf_config_path: str | None) -> tuple[str | None, str | None]:
    """
    ä» PerfAgent é…ç½®æ–‡ä»¶ä¸­æå–ä¼˜åŒ–ç›®æ ‡å’Œè¯­è¨€é…ç½®ã€‚
    """
    if not perf_config_path:
        return None, None

    try:
        with open(perf_config_path, encoding="utf-8") as f:
            config = yaml.safe_load(f) or {}

        opt_target = config.get("optimization", {}).get("target")
        language = config.get("language_cfg", {}).get("language")

        target_str = str(opt_target) if isinstance(opt_target, str) and opt_target.strip() else None
        language_str = str(language) if isinstance(language, str) and language.strip() else None

        return target_str, language_str
    except Exception:
        return None, None


def write_iteration_preds(base_dir: Path, logger) -> Path | None:
    """
    èšåˆå½“å‰è¿­ä»£å„å®ä¾‹çš„ç»“æœï¼Œç”Ÿæˆ preds.jsonã€‚
    """
    predictions = {}
    try:
        for instance_dir in base_dir.iterdir():
            if not instance_dir.is_dir():
                continue

            result_file = instance_dir / "result.json"
            if not result_file.exists():
                continue

            try:
                with open(result_file, encoding="utf-8") as f:
                    data = json.load(f)
            except Exception:
                continue

            instance_id = data.get("instance_id", instance_dir.name)
            code = data.get("optimized_code", "")
            final_perf = data.get("final_performance")

            # åªè¦ final_perf ä¸æ˜¯æ— ç©·å¤§ï¼Œå°±è®¤ä¸ºé€šè¿‡
            is_passed = False
            if final_perf is not None:
                try:
                    is_passed = not math.isinf(float(final_perf))
                except (ValueError, TypeError):
                    is_passed = False

            predictions[str(instance_id)] = {
                "code": code,
                "passed": is_passed,
                "runtime": final_perf,
            }

        preds_path = base_dir / "preds.json"
        with open(preds_path, "w", encoding="utf-8") as f:
            json.dump(predictions, f, indent=2, ensure_ascii=False)

        logger.info(f"å·²ç”Ÿæˆè¿­ä»£é¢„æµ‹æ±‡æ€»: {preds_path}")
        return preds_path

    except Exception as e:
        logger.warning(f"ç”Ÿæˆ preds.json å¤±è´¥: {e}")
        return None


def aggregate_all_iterations_preds(root_output_dir: Path, logger) -> Path | None:
    """
    æ±‡æ€»æ‰€æœ‰ iteration_* ç›®å½•ä¸‹çš„ preds.json åˆ°æ ¹ç›®å½•ã€‚
    """
    aggregated_data: dict[str, list[dict]] = {}

    try:
        # éå†æ‰€æœ‰è¿­ä»£ç›®å½•ï¼ŒæŒ‰æ•°å­—é¡ºåºæ’åº
        iteration_dirs = sorted(root_output_dir.glob("iteration_*"), key=lambda p: p.name)

        for iter_dir in iteration_dirs:
            if not iter_dir.is_dir():
                continue

            # è§£æè¿­ä»£å·
            try:
                iter_num = int(iter_dir.name.split("_")[-1])
            except ValueError:
                continue

            preds_file = iter_dir / "preds.json"
            if not preds_file.exists():
                continue

            try:
                with open(preds_file, encoding="utf-8") as f:
                    preds = json.load(f)
            except Exception:
                continue

            for instance_id, info in preds.items():
                try:
                    passed = bool(info.get("passed", False))
                    # æœªé€šè¿‡çš„å®ä¾‹ï¼Œcode ç½®ä¸ºç©ºå­—ç¬¦ä¸²
                    code = info.get("code", "") if passed else ""
                    runtime = info.get("runtime")

                    entry = {"iteration": iter_num, "code": code, "runtime": runtime}
                    aggregated_data.setdefault(str(instance_id), []).append(entry)
                except Exception:
                    continue

        agg_path = root_output_dir / "preds.json"
        with open(agg_path, "w", encoding="utf-8") as f:
            json.dump(aggregated_data, f, indent=2, ensure_ascii=False)

        logger.info(f"æ±‡æ€»æ‰€æœ‰è¿­ä»£é¢„æµ‹ç»“æœ: {agg_path}")
        return agg_path

    except Exception as e:
        logger.warning(f"æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None


def write_final_json_from_preds(aggregated_preds_path: Path, root_output_dir: Path, logger) -> Path | None:
    """
    ä»æ±‡æ€»çš„ preds.json ä¸­é€‰æ‹©æœ€ä½³ç»“æœï¼ˆruntime æœ€å°ï¼‰å†™å…¥ final.jsonã€‚
    """
    try:
        with open(aggregated_preds_path, encoding="utf-8") as f:
            aggregated_data = json.load(f)
    except Exception as e:
        logger.warning(f"è¯»å–æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None

    def _parse_runtime(rt_val):
        """è§£æ runtime å€¼ï¼Œå¼‚å¸¸æƒ…å†µè¿”å›æ— ç©·å¤§"""
        try:
            if rt_val is None:
                return float("inf")
            if isinstance(rt_val, (int, float)):
                return float(rt_val)
            if isinstance(rt_val, str):
                lowered = rt_val.strip().lower()
                if lowered in ("inf", "infinity", "nan"):
                    return float("inf")
                return float(rt_val)
            return float("inf")
        except Exception:
            return float("inf")

    final_result_map: dict[str, str] = {}

    try:
        for instance_id, entries in aggregated_data.items():
            if not isinstance(entries, list) or not entries:
                continue

            # æ‰¾åˆ° runtime æœ€å°çš„æ¡ç›®
            try:
                best_entry = min(entries, key=lambda e: _parse_runtime(e.get("runtime")))
            except ValueError:
                continue

            final_result_map[str(instance_id)] = best_entry.get("code", "") or ""

        final_path = root_output_dir / "final.json"
        with open(final_path, "w", encoding="utf-8") as f:
            json.dump(final_result_map, f, indent=2, ensure_ascii=False)

        logger.info(f"ç”Ÿæˆæœ€ç»ˆç»“æœ final.json: {final_path}")
        return final_path

    except Exception as e:
        logger.warning(f"ç”Ÿæˆ final.json å¤±è´¥: {e}")
        return None


def create_temp_perf_config(
    base_config_path: str | None,
    se_model_config: dict[str, Any],
    logger,
    extra_overrides: dict[str, Any] | None = None,
) -> Path | None:
    """
    ç”Ÿæˆä¸´æ—¶çš„ PerfAgent é…ç½®æ–‡ä»¶ã€‚
    """
    try:
        perf_config = {}
        if base_config_path:
            try:
                with open(base_config_path, encoding="utf-8") as f:
                    perf_config = yaml.safe_load(f) or {}
            except Exception as e:
                logger.warning(f"æ— æ³•è¯»å–åŸºç¡€é…ç½®æ–‡ä»¶ {base_config_path}: {e}")

        # æ¨¡å‹å‚æ•°è¦†ç›–ç™½åå•
        allowed_model_keys = {"name", "api_base", "api_key", "max_input_tokens", "max_output_tokens", "temperature"}

        model_overrides = {
            k: v
            for k, v in (se_model_config or {}).items()
            if k in allowed_model_keys and v is not None and str(v).strip() != ""
        }

        perf_config.setdefault("model", {}).update(model_overrides)

        # å…¶ä»–é¡¶å±‚å‚æ•°è¦†ç›–ï¼ˆå¦‚ max_iterationsï¼‰
        if extra_overrides:
            for key, val in extra_overrides.items():
                if val is not None and str(val).strip() != "":
                    # å°è¯•è½¬ä¸º intï¼Œå¦‚æœå¤±è´¥åˆ™ä¿æŒåŸå€¼
                    if key == "max_iterations":
                        try:
                            perf_config[key] = int(val)
                        except (ValueError, TypeError):
                            perf_config[key] = val
                    else:
                        perf_config[key] = val

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile("w", suffix=".yaml", delete=False) as tmp_file:
            yaml.safe_dump(perf_config, tmp_file, sort_keys=False, allow_unicode=True)
            temp_path = Path(tmp_file.name)

        logger.info(f"ç”Ÿæˆä¸´æ—¶ PerfAgent é…ç½®: {temp_path}")
        logger.debug(f"æ¨¡å‹è¦†ç›–å‚æ•°: {json.dumps(model_overrides, ensure_ascii=False)}")

        return temp_path

    except Exception as e:
        logger.warning(f"ç”Ÿæˆä¸´æ—¶é…ç½®å¤±è´¥: {e}")
        return None


def call_perfagent(iteration_params: dict[str, Any], logger, dry_run: bool = False) -> dict[str, Any]:
    """
    è°ƒç”¨ PerfAgent æ‰§è¡Œæ‰¹é‡ä¼˜åŒ–ã€‚
    """
    base_config_path = iteration_params.get("perf_base_config")
    output_dir = Path(iteration_params["output_dir"]).resolve()
    instances_dir = iteration_params.get("instances_dir")
    num_workers = iteration_params.get("num_workers", 1)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)

    try:
        # ç”Ÿæˆä¸´æ—¶é…ç½®
        se_model_config = iteration_params.get("model") or {}
        temp_config_path = create_temp_perf_config(
            base_config_path,
            se_model_config,
            logger,
            extra_overrides={
                "max_iterations": iteration_params.get("max_iterations"),
            },
        )

        # æ„å»ºå‘½ä»¤
        cmd = [sys.executable, "-m", "perfagent.run_batch"]

        # é…ç½®æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ä¸´æ—¶ç”Ÿæˆçš„ï¼‰
        config_path_to_use = temp_config_path if temp_config_path else base_config_path
        if config_path_to_use:
            cmd.extend(["--config", str(config_path_to_use)])

        cmd.extend(
            [
                "--instances-dir",
                str(instances_dir),
                "--base-dir",
                str(output_dir),
                "--max-workers",
                str(num_workers),
            ]
        )

        # ç®—å­ä¼ é€’çš„å‚æ•°
        operator_params = iteration_params.get("operator_params") or {}
        initial_code_dir = operator_params.get("initial_code_dir")
        instance_templates_dir = operator_params.get("instance_templates_dir")

        if initial_code_dir:
            cmd.extend(["--initial-code-dir", str(initial_code_dir)])
        if instance_templates_dir:
            cmd.extend(["--instance-templates-dir", str(instance_templates_dir)])

        cmd_str = " ".join(cmd)

        if dry_run:
            logger.info("æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡å®é™…æ‰§è¡Œ")
            print(f"ğŸš€ [DEMO] PerfAgent å‘½ä»¤é¢„è§ˆ: {cmd_str}")
            return {"status": "skipped", "reason": "dry_run", "preview_cmd": cmd_str}

        logger.info(f"æ‰§è¡Œ PerfAgent å‘½ä»¤: {cmd_str}")
        print(f"ğŸš€ æ‰§è¡Œ PerfAgent: {cmd_str}")

        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(cmd, cwd=str(Path(__file__).parent.parent), text=True)

        if result.returncode == 0:
            logger.info("PerfAgent æ‰§è¡ŒæˆåŠŸ")
            print("âœ… PerfAgent æ‰§è¡ŒæˆåŠŸ")
            # ç”Ÿæˆå½“å‰è¿­ä»£çš„é¢„æµ‹ç»“æœ
            preds_path = write_iteration_preds(output_dir, logger)
            return {
                "status": "success",
                "summary": "success",
                "base_dir": str(output_dir),
                "preds_file": str(preds_path) if preds_path else None,
            }
        else:
            logger.error(f"PerfAgent æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"âŒ PerfAgent æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return {"status": "failed", "returncode": result.returncode}

    except Exception as e:
        logger.error(f"è°ƒç”¨ PerfAgent å¼‚å¸¸: {e}", exc_info=True)
        return {"status": "error", "exception": str(e)}
    finally:
        # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤ä¸´æ—¶é…ç½®æ–‡ä»¶çš„é€»è¾‘ï¼Œå¦‚æœéœ€è¦çš„è¯
        pass


# --- è¾…åŠ©å‡½æ•° ---


def _process_and_summarize(
    iter_dir: Path,
    iter_idx: int,
    step_config: dict,
    se_config: dict,
    pool_manager: TrajPoolManager,
    logger,
    label_prefix=None,
    source_labels=None,
    source_labels_map=None,
    operator_name=None,
):
    """
    åå¤„ç†ï¼šç”Ÿæˆ .tra æ–‡ä»¶å¹¶æ›´æ–°è½¨è¿¹æ± 
    """
    try:
        processor = TrajectoryProcessor()
        tra_stats = processor.process_iteration_directory(iter_dir)

        if tra_stats and tra_stats.get("total_tra_files", 0) > 0:
            # æå–ä¼˜åŒ–ç›®æ ‡é…ç½®
            perf_cfg_path = step_config.get("perf_base_config")
            opt_target, lang_val = _extract_optimization_info(perf_cfg_path)

            # æ›´æ–° summarizer é…ç½®
            if opt_target or lang_val:
                pc = se_config.setdefault("prompt_config", {})
                if isinstance(pc, dict):
                    scfg = pc.setdefault("summarizer", {})
                    if opt_target:
                        scfg["optimization_target"] = opt_target
                    if lang_val:
                        scfg["language"] = lang_val

            _summarize_iteration_to_pool(
                iter_dir,
                iter_idx,
                pool_manager,
                se_config,
                logger,
                label_prefix=label_prefix,
                source_labels_map=source_labels_map,
                operator_name=operator_name,
            )
            try:
                mm = getattr(pool_manager, "memory_manager", None)
                if mm is not None:
                    mem = mm.load()
                    ckpt_path = Path(iter_dir) / f"memory_iter_{iter_idx}.json"
                    with open(ckpt_path, "w", encoding="utf-8") as f:
                        json.dump(mem, f, ensure_ascii=False, indent=2)
                    logger.info(f"å·²ä¿å­˜è¿­ä»£ {iter_idx} çš„è®°å¿†å¿«ç…§: {ckpt_path}")
            except Exception as e:
                logger.warning(f"ä¿å­˜è¿­ä»£ {iter_idx} è®°å¿†å¿«ç…§å¤±è´¥: {e}")
        else:
            logger.warning(f"è¿­ä»£ {iter_idx} æœªç”Ÿæˆ .tra æ–‡ä»¶")
    except Exception as e:
        logger.error(f"è¿­ä»£ {iter_idx} åå¤„ç†å¤±è´¥: {e}")


def _print_final_summary(se_config, timestamp, log_file, output_dir, traj_pool_manager, logger):
    """
    æ‰“å°å’Œè®°å½•æœ€ç»ˆæ‰§è¡Œæ‘˜è¦
    """
    logger.info("æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    print("\nğŸ¯ æ‰§è¡Œå®Œæˆ")
    print(f"  æ—¥å¿—: {log_file}")
    print(f"  è¾“å‡º: {output_dir}")

    # æ±‡æ€» preds.json å¹¶ç”Ÿæˆ final.json
    try:
        root_dir = Path(output_dir)
        agg_path = aggregate_all_iterations_preds(root_dir, logger)
        if agg_path:
            write_final_json_from_preds(agg_path, root_dir, logger)
    except Exception as e:
        logger.warning(f"ç”Ÿæˆæœ€ç»ˆç»“æœæ–‡ä»¶å¤±è´¥: {e}")

    # ç»Ÿè®¡ Token
    _log_token_usage(output_dir, logger)


def _log_token_usage(output_dir, logger):
    """
    ç»Ÿè®¡å¹¶è®°å½• Token ä½¿ç”¨æƒ…å†µ
    """
    token_log_file = Path(output_dir) / "token_usage.jsonl"
    if not token_log_file.exists():
        return

    total_prompt = 0
    total_completion = 0
    total = 0
    by_context: dict[str, dict[str, int]] = {}

    try:
        with open(token_log_file, encoding="utf-8") as f:
            for line in f:
                try:
                    rec = json.loads(line)
                    pt = int(rec.get("prompt_tokens") or 0)
                    ct = int(rec.get("completion_tokens") or 0)
                    tt = int(rec.get("total_tokens") or (pt + ct))
                    ctx = str(rec.get("context") or "unknown")

                    total_prompt += pt
                    total_completion += ct
                    total += tt

                    agg = by_context.setdefault(ctx, {"prompt": 0, "completion": 0, "total": 0})
                    agg["prompt"] += pt
                    agg["completion"] += ct
                    agg["total"] += tt
                except Exception:
                    continue

        print("\nğŸ“ˆ Token ä½¿ç”¨ç»Ÿè®¡:")
        print(f"  Total: {total} (Prompt: {total_prompt}, Completion: {total_completion})")
        if by_context:
            print("  æŒ‰ä¸Šä¸‹æ–‡åˆ†ç±»:")
            for ctx, vals in by_context.items():
                print(f"    - {ctx}: prompt={vals['prompt']}, completion={vals['completion']}, total={vals['total']}")

        logger.info(
            json.dumps(
                {
                    "token_usage_total": {"prompt": total_prompt, "completion": total_completion, "total": total},
                    "by_context": by_context,
                    "token_log_file": str(token_log_file),
                },
                ensure_ascii=False,
            )
        )
    except Exception:
        pass


# --- ä¸»æµç¨‹ ---


def main():
    """
    ä¸»å‡½æ•°ï¼šç­–ç•¥é©±åŠ¨çš„ PerfAgent å¤šè¿­ä»£æ‰§è¡Œå…¥å£ã€‚
    """
    parser = argparse.ArgumentParser(description="SE æ¡†æ¶ PerfAgent å¤šè¿­ä»£æ‰§è¡Œè„šæœ¬")
    parser.add_argument("--config", default="SE/configs/se_configs/dpsk.yaml", help="SE é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--mode", choices=["demo", "execute"], default="execute", help="è¿è¡Œæ¨¡å¼")
    args = parser.parse_args()

    print("=== SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œ ===")

    try:
        # 1. åŠ è½½é…ç½®
        with open(args.config, encoding="utf-8") as f:
            se_config = yaml.safe_load(f)

        # 2. å‡†å¤‡è¾“å‡ºç¯å¢ƒ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = se_config["output_dir"].replace("{timestamp}", timestamp)

        # åˆå§‹åŒ–æ—¥å¿—
        log_file = setup_se_logging(output_dir)
        logger = get_se_logger("perf_run", emoji="âš¡")

        logger.info(f"å¯åŠ¨æ‰§è¡Œ: {args.config}, æ¨¡å¼: {args.mode}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")

        # Tokenç»Ÿè®¡ä¸LLM I/Oæ—¥å¿—æ–‡ä»¶è·¯å¾„
        os.environ["SE_TOKEN_LOG_PATH"] = str(Path(output_dir) / "token_usage.jsonl")
        os.environ["SE_LLM_IO_LOG_PATH"] = str(Path(output_dir) / "llm_io.jsonl")

        # 3. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        traj_pool_path = os.path.join(output_dir, "traj.pool")

        # LLM Client
        llm_client = None
        try:
            from core.utils.llm_client import LLMClient

            llm_client = LLMClient.from_se_config(se_config, use_operator_model=True)
        except Exception as e:
            logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

        # Local Memory Manager
        local_memory = None
        memory_config = se_config.get("local_memory")
        if isinstance(memory_config, dict) and memory_config.get("enabled", True):
            try:
                memory_path = Path(output_dir) / "memory.json"
                local_memory = LocalMemoryManager(memory_path, llm_client=llm_client)
                local_memory.initialize()
                logger.info("LocalMemoryManager å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"LocalMemoryManager åˆå§‹åŒ–å¤±è´¥: {e}")

        local_memory_text = None
        try:
            if local_memory is not None:
                mem = local_memory.load()
                local_memory_text = local_memory.render_as_markdown(mem)
        except Exception:
            local_memory_text = None

        # Trajectory Pool Manager
        traj_pool_manager = TrajPoolManager(
            traj_pool_path,
            llm_client,
            num_workers=se_config.get("num_workers"),
            memory_manager=local_memory,
            prompt_config=se_config.get("prompt_config"),
        )
        traj_pool_manager.initialize_pool()

        # 4. æ‰§è¡Œè¿­ä»£ç­–ç•¥
        iterations = se_config.get("strategy", {}).get("iterations", [])
        logger.info(f"è®¡åˆ’æ‰§è¡Œ {len(iterations)} ä¸ªè¿­ä»£æ­¥éª¤")

        # ç¡®å®šèµ·å§‹è¿­ä»£ç¼–å·
        existing_iters = [int(p.name.split("_")[-1]) for p in Path(output_dir).glob("iteration_*") if p.is_dir()]
        next_iteration_idx = (max(existing_iters) if existing_iters else 0) + 1

        for step_config in iterations:
            operator_name = step_config.get("operator")
            is_filter_operator = str(operator_name) in ("filter", "filter_trajectories")

            # æ„å»ºå½“å‰è¿­ä»£çš„åŸºç¡€å‚æ•°
            current_iter_dir = f"{output_dir}/iteration_{next_iteration_idx}"
            iter_params = {
                "perf_base_config": step_config.get("perf_base_config"),
                "operator": operator_name,
                "model": se_config.get("model", {}),
                "instances_dir": se_config.get("instances", {}).get("instances_dir", ""),
                "output_dir": current_iter_dir,
                "max_iterations": se_config.get("max_iterations", 10),
                "num_workers": se_config.get("num_workers", 1),
            }

            try:
                if local_memory is not None:
                    _mem_latest = local_memory.load()
                    local_memory_text = local_memory.render_as_markdown(_mem_latest)
            except Exception:
                pass

            # --- åˆ†æ”¯ A: Plan ç®—å­ (ç‰¹æ®Šå¤„ç†: å±•å¼€ä¸ºå¤šå®ä¾‹é…ç½®) ---
            if operator_name == "plan":
                logger.info("æ‰§è¡Œç®—å­: Plan")
                # æ„å»º Plan ç®—å­å‚æ•°
                plan_step = {
                    "operator": "plan",
                    "num": step_config.get("num"),
                    "trajectory_labels": step_config.get("trajectory_labels"),
                }
                op_result = _execute_operator_step(plan_step, se_config, traj_pool_manager, output_dir, logger)

                plans = op_result.get("plans") or []
                for plan in plans:
                    # ä¸ºæ¯ä¸ª plan åˆ›å»ºå•ç‹¬çš„è¿­ä»£ç›®å½•
                    plan_iter_dir = f"{output_dir}/iteration_{next_iteration_idx}"
                    plan_label = plan.get("label")
                    per_inst_reqs = plan.get("per_instance_requirements") or {}

                    # å‡†å¤‡ system_prompt ç›®å½•
                    sys_prompt_dir = Path(plan_iter_dir) / "system_prompt"
                    sys_prompt_dir.mkdir(parents=True, exist_ok=True)

                    rendered_template = None
                    try:
                        base_cfg_path = step_config.get("perf_base_config")
                        if base_cfg_path:
                            with open(base_cfg_path, encoding="utf-8") as f:
                                base_cfg_data = yaml.safe_load(f) or {}
                            tmpl = (base_cfg_data.get("prompts", {}) or {}).get("system_template")
                            if isinstance(tmpl, str) and tmpl:
                                if local_memory_text:
                                    rendered_template = tmpl.replace("{local_memory}", str(local_memory_text))
                                else:
                                    rendered_template = tmpl
                    except Exception:
                        rendered_template = None

                    for inst_name, req in per_inst_reqs.items():
                        try:
                            data = {"prompts": {"additional_requirements": str(req)}}
                            if isinstance(rendered_template, str) and rendered_template:
                                data["prompts"]["system_template"] = rendered_template
                            with open(sys_prompt_dir / f"{inst_name}.yaml", "w", encoding="utf-8") as f:
                                yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)
                        except Exception:
                            pass

                    # æ›´æ–°è¿­ä»£å‚æ•°
                    iter_params["output_dir"] = plan_iter_dir
                    iter_params["operator_params"] = {"instance_templates_dir": str(sys_prompt_dir)}

                    print(f"\n=== è¿­ä»£ {next_iteration_idx} (Plan: {plan_label}) ===")

                    # æ‰§è¡Œ PerfAgent
                    run_result = call_perfagent(iter_params, logger, dry_run=(args.mode == "demo"))

                    # åå¤„ç†ï¼šç”Ÿæˆè½¨è¿¹
                    if run_result.get("status") == "success" and args.mode == "execute":
                        _process_and_summarize(
                            Path(plan_iter_dir),
                            next_iteration_idx,
                            step_config,
                            se_config,
                            traj_pool_manager,
                            logger,
                            label_prefix=plan_label,
                            operator_name=operator_name,
                        )

                    next_iteration_idx += 1
                continue

            # --- åˆ†æ”¯ B: æ™®é€šç®—å­æˆ–æ— ç®—å­ ---
            initial_code_dir = None
            instance_templates_dir = None
            source_labels_map = None

            if operator_name:
                logger.info(f"æ‰§è¡Œç®—å­: {operator_name}")

                # å‡†å¤‡ç®—å­è¾“å…¥
                src_labels = []
                if isinstance(step_config.get("source_trajectories"), list):
                    src_labels = [str(x) for x in step_config.get("source_trajectories")]
                elif step_config.get("source_trajectory"):
                    src_labels = [str(step_config.get("source_trajectory"))]

                op_step_config = {
                    "operator": operator_name,
                    "inputs": [{"label": l} for l in src_labels],
                    "outputs": [{"label": str(step_config.get("trajectory_label"))}]
                    if step_config.get("trajectory_label")
                    else [],
                    "strategy": step_config.get("filter_strategy") or step_config.get("strategy") or {},
                }

                op_result = _execute_operator_step(
                    op_step_config, se_config, traj_pool_manager, current_iter_dir, logger
                )

                initial_code_dir = op_result.get("initial_code_dir")
                instance_templates_dir = op_result.get("instance_templates_dir")
                source_labels_map = op_result.get("source_entry_labels_per_instance")

                # Filter ç®—å­ç‰¹æ®Šé€»è¾‘ï¼šè·³è¿‡ PerfAgent æ‰§è¡Œ
                if is_filter_operator:
                    logger.info("Filter ç®—å­æ‰§è¡Œå®Œæ¯•ï¼Œè·³è¿‡åç»­ PerfAgent è¿è¡Œ")
                    continue

                rendered_template = None
                try:
                    base_cfg_path = step_config.get("perf_base_config")
                    if base_cfg_path:
                        with open(base_cfg_path, encoding="utf-8") as f:
                            base_cfg_data = yaml.safe_load(f) or {}
                        tmpl = (base_cfg_data.get("prompts", {}) or {}).get("system_template")
                        if isinstance(tmpl, str) and tmpl:
                            if local_memory_text:
                                rendered_template = tmpl.replace("{local_memory}", str(local_memory_text))
                            else:
                                rendered_template = tmpl
                except Exception:
                    rendered_template = None

                if isinstance(rendered_template, str) and rendered_template:
                    try:
                        if instance_templates_dir:
                            p = Path(instance_templates_dir)
                            if p.exists():
                                for fp in p.glob("*.yaml"):
                                    try:
                                        with open(fp, encoding="utf-8") as f:
                                            d = yaml.safe_load(f) or {}
                                        pm = d.get("prompts") or {}
                                        pm["system_template"] = rendered_template
                                        d["prompts"] = pm
                                        with open(fp, "w", encoding="utf-8") as f:
                                            yaml.safe_dump(d, f, allow_unicode=True, sort_keys=False)
                                    except Exception:
                                        pass
                        else:
                            sys_prompt_dir = Path(current_iter_dir) / "system_prompt"
                            sys_prompt_dir.mkdir(parents=True, exist_ok=True)
                            inst_dir = Path(iter_params.get("instances_dir") or "")
                            for fp in inst_dir.glob("*.json"):
                                try:
                                    with open(sys_prompt_dir / f"{fp.stem}.yaml", "w", encoding="utf-8") as f:
                                        yaml.safe_dump(
                                            {"prompts": {"system_template": rendered_template}},
                                            f,
                                            allow_unicode=True,
                                            sort_keys=False,
                                        )
                                except Exception:
                                    pass
                            instance_templates_dir = str(sys_prompt_dir)
                    except Exception:
                        pass

            # è®¾ç½®ç®—å­è¾“å‡ºå‚æ•°
            iter_params["operator_params"] = {}
            if initial_code_dir:
                iter_params["operator_params"]["initial_code_dir"] = initial_code_dir
            if instance_templates_dir:
                iter_params["operator_params"]["instance_templates_dir"] = instance_templates_dir

            print(f"\n=== è¿­ä»£ {next_iteration_idx} ===")

            # æ‰§è¡Œ PerfAgent
            run_result = call_perfagent(iter_params, logger, dry_run=(args.mode == "demo"))

            # åå¤„ç†
            if run_result.get("status") == "success" and args.mode == "execute":
                # ç¡®å®šæºæ ‡ç­¾ç”¨äºè®°å½•
                src_labels_for_summary = []
                if isinstance(step_config.get("source_trajectories"), list):
                    src_labels_for_summary = [str(x) for x in step_config.get("source_trajectories")]

                _process_and_summarize(
                    Path(current_iter_dir),
                    next_iteration_idx,
                    step_config,
                    se_config,
                    traj_pool_manager,
                    logger,
                    label_prefix=step_config.get("trajectory_label"),
                    source_labels=src_labels_for_summary,
                    source_labels_map=source_labels_map,
                    operator_name=operator_name,
                )

            next_iteration_idx += 1

        # 5. æœ€ç»ˆæ±‡æ€»
        _print_final_summary(se_config, timestamp, log_file, output_dir, traj_pool_manager, logger)

    except Exception as e:
        if "logger" in locals():
            logger.error(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {e}", exc_info=True)
        print(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
