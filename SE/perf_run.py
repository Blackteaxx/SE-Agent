#!/usr/bin/env python3
"""
PerfAgent é›†æˆæ‰§è¡Œè„šæœ¬
æ¨¡ä»¿ SE/basic_run.py çš„ç»“æ„ï¼Œåœ¨ SE æ¡†æ¶ä¸­é©±åŠ¨ perfagent çš„å•/å¤šå®ä¾‹æ€§èƒ½ä¼˜åŒ–ã€‚
"""

import argparse
import json
import math
import os
import subprocess
import sys
import tempfile
from datetime import datetime
from pathlib import Path

import yaml

# æ·»åŠ SEç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥SEæ—¥å¿—ç³»ç»Ÿ
from core.utils.se_logger import get_se_logger, setup_se_logging
from core.utils.traj_extractor import TrajExtractor
from core.utils.traj_pool_manager import TrajPoolManager
from core.utils.trajectory_processor import TrajectoryProcessor

# å¯¼å…¥operatorç³»ç»Ÿ
from operators import create_operator


def call_operator(operator_name, workspace_dir, current_iteration, se_config, logger):
    """
    è°ƒç”¨æŒ‡å®šçš„operatorå¤„ç†

    Args:
        operator_name: operatoråç§°
        workspace_dir: å·¥ä½œç©ºé—´æ ¹ç›®å½• (ä¸å¸¦è¿­ä»£å·)
        current_iteration: å½“å‰è¿­ä»£å·
        se_config: SEé…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        operatorè¿”å›çš„å‚æ•°å­—å…¸ (å¦‚ {'instance_templates_dir': 'path'}) æˆ– Noneè¡¨ç¤ºå¤±è´¥
    """
    try:
        logger.info(f"å¼€å§‹è°ƒç”¨operator: {operator_name}")

        # åŠ¨æ€åˆ›å»ºoperatorå®ä¾‹
        operator = create_operator(operator_name, se_config)
        if not operator:
            logger.error(f"æ— æ³•åˆ›å»ºoperatorå®ä¾‹: {operator_name}")
            return None

        logger.info(f"æˆåŠŸåˆ›å»ºoperatorå®ä¾‹: {operator.__class__.__name__}")

        # è°ƒç”¨operator.process()æ–¹æ³•
        result = operator.process(
            workspace_dir=workspace_dir,
            current_iteration=current_iteration,
            num_workers=se_config.get("num_workers", 1),
        )

        if result:
            logger.info(f"Operator {operator_name} æ‰§è¡ŒæˆåŠŸï¼Œè¿”å›: {list(result.keys())}")
            return result
        else:
            logger.warning(f"Operator {operator_name} æ‰§è¡ŒæˆåŠŸä½†è¿”å›ç©ºç»“æœ")
            return None

    except Exception as e:
        logger.error(f"Operator {operator_name} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return None


def write_iteration_preds(base_dir: Path, logger) -> Path | None:
    """
    èšåˆå½“å‰è¿­ä»£å„å®ä¾‹çš„ç»“æœï¼Œç”Ÿæˆ preds.jsonã€‚

    - passedï¼šç›´æ¥ä¾æ® final_performance æ˜¯å¦ä¸º infï¼ˆæˆ–å­—ç¬¦ä¸²è¡¨ç¤ºçš„æ— ç©·ï¼‰åˆ¤æ–­ã€‚
    - runtimeï¼šè¾“å‡ºæœ€ç»ˆæ€§èƒ½å€¼ï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œå¦åˆ™å›é€€åˆ°åˆå§‹è¯„ä¼°çš„ä¿®å‰ªå‡å€¼ã€‚
    - codeï¼šä¼˜å…ˆä½¿ç”¨ optimized_codeï¼Œå›é€€åˆ° initial_codeã€‚

    è¿”å›ç”Ÿæˆçš„ preds.json è·¯å¾„ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    preds = {}
    try:
        for inst_dir in base_dir.iterdir():
            if not inst_dir.is_dir():
                continue
            res_file = inst_dir / "result.json"
            if not res_file.exists():
                continue
            try:
                with open(res_file, encoding="utf-8") as f:
                    data = json.load(f)
            except Exception:
                continue

            instance_id = data.get("instance_id", inst_dir.name)
            code = data.get("optimized_code", "")

            # è¯»å–æœ€ç»ˆæ€§èƒ½å€¼å¹¶ç”¨äº passed åˆ¤æ–­
            final_perf = data.get("final_performance")

            # runtimeï¼šä¼˜å…ˆ final_performanceï¼Œå¦åˆ™ initial trimmed_mean
            runtime = final_perf

            # passedï¼šfinal_performance ä¸º inf åˆ™ Falseï¼Œå¦åˆ™ True
            passed = not math.isinf(float(final_perf)) if final_perf is not None else False
            preds[str(instance_id)] = {
                "code": code,
                "passed": passed,
                "runtime": runtime,
            }

        preds_path = base_dir / "preds.json"
        with open(preds_path, "w", encoding="utf-8") as pf:
            json.dump(preds, pf, indent=2, ensure_ascii=False)
        print(f"ğŸ“ å·²ç”Ÿæˆ preds.json: {preds_path}")
        logger.info(f"å·²ç”Ÿæˆ preds.json: {preds_path}")
        return preds_path
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ preds.json å¤±è´¥: {e}")
        return None


def aggregate_all_iterations_preds(root_output_dir: Path, logger) -> Path | None:
    """
    æ±‡æ€»æ‰€æœ‰ iteration_* ç›®å½•ä¸‹çš„ preds.jsonï¼Œæ·»åŠ è¿­ä»£å·å¹¶å†™å…¥è¿è¡Œæ ¹ç›®å½•çš„ preds.jsonã€‚

    å˜æ›´ï¼šä¸å†è¿‡æ»¤æœªé€šè¿‡é¡¹ã€‚å¯¹äºæœªé€šè¿‡çš„å®ä¾‹ï¼Œå…¶ code å­—æ®µæ˜ç¡®è®¾ä¸ºç©ºå­—ç¬¦ä¸²""ï¼Œä»¥é¿å…åç»­è¾“å‡ºç¼ºå¤±ã€‚

    è¾“å‡ºç»“æ„ç¤ºä¾‹ï¼š
    {
      "inst1": [
        {"iteration": 1, "code": "...", "runtime": 1.23},
        {"iteration": 2, "code": "...", "runtime": 1.11}
      ],
      "inst2": [
        {"iteration": 2, "code": "", "runtime": "Infinity"}
      ]
    }
    """
    aggregated: dict[str, list[dict]] = {}
    try:
        for iter_dir in sorted(root_output_dir.glob("iteration_*")):
            if not iter_dir.is_dir():
                continue
            # è§£æè¿­ä»£å·
            try:
                iter_num = int(iter_dir.name.split("_")[-1])
            except Exception:
                iter_num = None

            preds_file = iter_dir / "preds.json"
            if not preds_file.exists():
                continue
            try:
                with open(preds_file, encoding="utf-8") as pf:
                    preds = json.load(pf)
            except Exception:
                continue

            for instance_id, info in preds.items():
                try:
                    passed = bool(info.get("passed", False))
                    # æœªé€šè¿‡çš„å®ä¾‹ï¼Œcode æ˜ç¡®ç½®ä¸ºç©ºå­—ç¬¦ä¸²
                    code = info.get("code", "") if passed else ""
                    runtime = info.get("runtime")
                    entry = {"iteration": iter_num, "code": code, "runtime": runtime}
                    aggregated.setdefault(str(instance_id), []).append(entry)
                except Exception:
                    continue

        agg_path = root_output_dir / "preds.json"
        with open(agg_path, "w", encoding="utf-8") as f:
            json.dump(aggregated, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ æ±‡æ€» preds.json: {agg_path}")
        logger.info(f"æ±‡æ€» preds.json: {agg_path}")
        return agg_path
    except Exception as e:
        logger.warning(f"æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None


def write_final_json_from_preds(aggregated_preds_path: Path, root_output_dir: Path, logger) -> Path | None:
    """
    ä»è¿è¡Œæ ¹ç›®å½•çš„ preds.jsonï¼ˆæ±‡æ€»ï¼‰é€‰æ‹©æ¯ä¸ªå®ä¾‹ runtime æœ€å°çš„è§£ï¼Œå†™å…¥ final.jsonã€‚

    æ–‡ä»¶ç»“æ„ï¼š
    {
      "instance_name": "code"
    }
    """
    try:
        with open(aggregated_preds_path, encoding="utf-8") as f:
            aggregated = json.load(f)
    except Exception as e:
        logger.warning(f"è¯»å–æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None

    def to_float(rt):
        try:
            if rt is None:
                return float("inf")
            if isinstance(rt, (int, float)):
                return float(rt)
            if isinstance(rt, str):
                lowered = rt.strip().lower()
                if lowered in ("inf", "infinity", "nan"):
                    return float("inf")
                return float(rt)
            return float("inf")
        except Exception:
            return float("inf")

    final_map: dict[str, str] = {}
    try:
        # å…ˆæ ¹æ®æœ€å° runtime é€‰æ‹©æœ€ä½³è§£ï¼›è‹¥å‡æœªé€šè¿‡ï¼ˆruntime ä¸º infï¼‰ï¼Œcode ä¼šæ˜¯ç©ºå­—ç¬¦ä¸²
        for instance_id, entries in aggregated.items():
            if not isinstance(entries, list) or not entries:
                continue
            try:
                best = min(entries, key=lambda e: to_float(e.get("runtime")))
            except Exception:
                continue
            final_map[str(instance_id)] = best.get("code", "") or ""

        # æ³¨ï¼šä¸å†è¿›è¡Œâ€œè¡¥é½ç©ºå­—ç¬¦ä¸²â€ï¼Œfinal.json ä»…ä¾æ®æ±‡æ€» preds.json çš„æœ€å° runtime é€‰æ‹©ç»“æœã€‚

        final_path = root_output_dir / "final.json"
        with open(final_path, "w", encoding="utf-8") as f:
            json.dump(final_map, f, indent=2, ensure_ascii=False)
        print(f"ğŸ ç”Ÿæˆ final.json: {final_path}")
        logger.info(f"ç”Ÿæˆ final.json: {final_path}")
        return final_path
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ final.json å¤±è´¥: {e}")
        return None


def create_temp_perf_config(
    base_config_path: str | None,
    se_model_cfg: dict,
    logger,
    extra_overrides: dict | None = None,
) -> Path | None:
    """åŸºäºåŸºç¡€é…ç½®ç”Ÿæˆä¸€ä¸ªä¸´æ—¶ PerfAgent é…ç½®æ–‡ä»¶ï¼Œå¹¶æŒ‰éœ€è¦†ç›–å­—æ®µã€‚

    - è¦†ç›–æ¨¡å‹ç›¸å…³å­—æ®µï¼ˆæ¥è‡ª SE ä¸»æ¨¡å‹è®¾ç½®ï¼‰
    - è¦†ç›–é¡¶å±‚æ§åˆ¶å­—æ®µï¼ˆç›®å‰æ”¯æŒ max_iterationsï¼‰ï¼Œç”¨äºä¸ SE é…ç½®å¯¹é½

    è¿”å›ä¸´æ—¶é…ç½®æ–‡ä»¶è·¯å¾„ï¼›è‹¥å¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    try:
        perf_cfg = {}
        if base_config_path:
            with open(base_config_path, encoding="utf-8") as f:
                perf_cfg = yaml.safe_load(f) or {}

        # ä»…è¦†ç›– PerfAgent æ”¯æŒçš„æ¨¡å‹å­—æ®µ
        allowed_keys = [
            "name",
            "api_base",
            "api_key",
            "max_input_tokens",
            "max_output_tokens",
            "temperature",
        ]
        override_model = {
            k: v
            for k, v in (se_model_cfg or {}).items()
            if k in allowed_keys and v is not None and (str(v).strip() != "")
        }

        perf_cfg.setdefault("model", {})
        perf_cfg["model"].update(override_model)

        # é¡¶å±‚è¦†ç›–ï¼šæ”¯æŒä» SE é…ç½®ä¼ å…¥çš„ max_iterations
        if extra_overrides:
            if "max_iterations" in extra_overrides:
                mi = extra_overrides.get("max_iterations")
                if mi is not None and str(mi).strip() != "":
                    try:
                        perf_cfg["max_iterations"] = int(mi)
                    except Exception:
                        # è‹¥æ— æ³•è½¬æ¢ä¸ºæ•´æ•°ï¼Œä»æŒ‰åŸå€¼å†™å…¥ï¼Œé¿å…ä¸­æ–­
                        perf_cfg["max_iterations"] = mi

        # ç”Ÿæˆä¸´æ—¶ YAML æ–‡ä»¶
        tmp = tempfile.NamedTemporaryFile("w", suffix=".yaml", delete=False)
        yaml.safe_dump(perf_cfg, tmp, sort_keys=False, allow_unicode=True)
        tmp_path = Path(tmp.name)
        tmp.close()

        print(f"ğŸ§© å·²ç”Ÿæˆä¸´æ—¶PerfAgenté…ç½®: {tmp_path}")
        logger.info(f"ä¸´æ—¶PerfAgenté…ç½®(æ¨¡å‹è¦†ç›–): {json.dumps(override_model, ensure_ascii=False)}")
        if extra_overrides and "max_iterations" in extra_overrides:
            logger.info(f"ä¸´æ—¶PerfAgenté…ç½®(è¿­ä»£è¦†ç›–): max_iterations={perf_cfg.get('max_iterations')}")
        return tmp_path
    except Exception as e_cfg:
        logger.warning(f"ç”Ÿæˆä¸´æ—¶PerfAgenté…ç½®å¤±è´¥: {e_cfg}")
        return None


def call_perfagent(iteration_params, logger, dry_run=False):
    """
    ç›´æ¥è°ƒç”¨ perfagent.run_batch çš„æ‰¹é‡æ‰§è¡Œæ¥å£ï¼Œè¿è¡Œæœ¬æ¬¡è¿­ä»£çš„å®ä¾‹ä¼˜åŒ–
    """
    base_config_path = iteration_params.get("perf_base_config")

    try:
        # åŸºç¡€é…ç½® + SE ä¸»æ¨¡å‹é…ç½®è¦†ç›– => ç”Ÿæˆä¸´æ—¶ PerfAgent é…ç½®
        logger.debug(f"ä½¿ç”¨PerfAgentåŸºç¡€é…ç½®: {base_config_path}")

        if dry_run:
            logger.warning("æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡PerfAgentå®é™…æ‰§è¡Œ")
            return {"status": "skipped", "reason": "dry_run"}

        # ç›®æ ‡è·¯å¾„å’Œå‘½ä»¤ï¼ˆæ‰¹é‡æ‰§è¡Œè„šæœ¬ï¼‰
        se_root = Path(__file__).parent
        project_root = se_root.parent

        # é€‰æ‹©å®ä¾‹ç›®å½•
        instances_dir = iteration_params.get("instances_dir")

        # åŸºç¡€ç›®å½•ï¼šä½¿ç”¨å½“å‰è¿­ä»£çš„è¾“å‡ºç›®å½•ï¼Œè®©æ¯ä¸ªå®ä¾‹åœ¨å…¶å­ç›®å½•ä¸‹ç”Ÿæˆæ—¥å¿—ä¸è½¨è¿¹
        base_dir = Path(iteration_params["output_dir"]).resolve()
        base_dir.mkdir(parents=True, exist_ok=True)

        # å°è£…ï¼šç”Ÿæˆä¸´æ—¶é…ç½®ï¼ˆåŒ…å«æ¨¡å‹è¦†ç›–ï¼‰ï¼›å¤±è´¥åˆ™å›é€€åˆ°åŸºç¡€é…ç½®
        se_model_cfg = iteration_params.get("model") or {}
        if base_config_path:
            print(f"ğŸ“‹ ä½¿ç”¨åŸºç¡€é…ç½®æ–‡ä»¶: {base_config_path}")
        temp_config_path = (
            create_temp_perf_config(
                base_config_path,
                se_model_cfg,
                logger,
                extra_overrides={
                    "max_iterations": iteration_params.get("max_iterations"),
                },
            )
            or base_config_path
        )

        # ä¼˜å…ˆä½¿ç”¨åŸºç¡€é…ç½®ï¼›å¦‚æœæä¾› instance_templates_dirï¼Œåˆ™äº¤ç”± run_batch åšæ¯ä»»åŠ¡åˆå¹¶
        # ç»„è£…å‘½ä»¤ï¼šå…ˆæ”¾ --configï¼ˆè‹¥æœ‰ï¼‰ï¼Œå†ä¾æ¬¡åŠ å…¥å…¶ä»–å‚æ•°ï¼Œé¿å…è§£æå†²çª
        cmd = [sys.executable, "-m", "perfagent.run_batch"]
        if temp_config_path:
            cmd.extend(["--config", str(temp_config_path)])
        cmd.extend(
            [
                "--instances-dir",
                str(instances_dir),
                "--base-dir",
                str(base_dir),
                "--max-workers",
                str(iteration_params.get("num_workers", 1)),
            ]
        )

        # è‹¥ operator è¿”å› instance_templates_dirï¼Œåˆ™ä¼ ç»™ run_batch åšæ¯ä»»åŠ¡åˆå¹¶
        operator_params = iteration_params.get("operator_params", {}) or {}
        itd = operator_params.get("instance_templates_dir")
        if itd:
            cmd.extend(["--instance-templates-dir", str(itd)])

        print(f"ğŸš€ æ‰§è¡ŒPerfAgentæ‰¹é‡å‘½ä»¤: {' '.join(cmd)}")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {project_root}")
        print("=" * 60)

        result = subprocess.run(cmd, cwd=str(project_root), text=True)

        print("=" * 60)
        if result.returncode == 0:
            logger.info("PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡ŒæˆåŠŸ")
            print("âœ… PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡ŒæˆåŠŸ")

            preds_path = write_iteration_preds(base_dir, logger)
            return {
                "status": "success",
                "summary": "success",
                "base_dir": str(base_dir),
                "preds_file": str(preds_path) if preds_path else None,
            }
        else:
            logger.error(f"PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"âŒ PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return {"status": "failed", "returncode": result.returncode}

    except Exception as e:
        logger.error(f"è°ƒç”¨PerfAgentæ—¶å‡ºé”™: {e}", exc_info=True)
        return {"status": "error", "exception": str(e)}
    finally:
        # æ— ä¸´æ—¶é…ç½®éœ€è¦æ¸…ç†
        pass


def main():
    """ä¸»å‡½æ•°ï¼šç­–ç•¥é©±åŠ¨çš„ PerfAgent å¤šè¿­ä»£æ‰§è¡Œ"""

    parser = argparse.ArgumentParser(description="SE æ¡†æ¶ PerfAgent å¤šè¿­ä»£æ‰§è¡Œè„šæœ¬")
    parser.add_argument("--config", default="SE/configs/se_configs/dpsk.yaml", help="SE é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--mode", choices=["demo", "execute"], default="execute", help="è¿è¡Œæ¨¡å¼: demo=æ¼”ç¤ºæ¨¡å¼, execute=ç›´æ¥æ‰§è¡Œ"
    )
    args = parser.parse_args()

    print("=== SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œ ===")
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")

    try:
        # è¯»å– SE é…ç½®æ–‡ä»¶
        with open(args.config, encoding="utf-8") as f:
            se_config = yaml.safe_load(f)

        # ç”Ÿæˆ timestamp å¹¶æ›¿æ¢è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = se_config["output_dir"].replace("{timestamp}", timestamp)

        # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
        log_file = setup_se_logging(output_dir)
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")

        logger = get_se_logger("perf_run", emoji="âš¡")
        logger.info("SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œå¯åŠ¨")
        logger.debug(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        logger.info(f"ç”Ÿæˆtimestamp: {timestamp}")
        logger.info(f"å®é™…è¾“å‡ºç›®å½•: {output_dir}")

        # åˆå§‹åŒ–è½¨è¿¹æ± ç®¡ç†å™¨
        traj_pool_path = os.path.join(output_dir, "traj.pool")

        # åˆ›å»ºLLMå®¢æˆ·ç«¯ç”¨äºè½¨è¿¹æ€»ç»“
        llm_client = None
        try:
            from core.utils.llm_client import LLMClient

            # ä½¿ç”¨operator_modelsé…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¸»æ¨¡å‹é…ç½®
            llm_client = LLMClient.from_se_config(se_config, use_operator_model=True)
            logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {llm_client.config['name']}")
        except Exception as e:
            logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ€»ç»“: {e}")

        # å°† se_config ä¸­çš„å¹¶å‘æ§åˆ¶ä¼ å…¥ TrajPoolManager
        traj_pool_manager = TrajPoolManager(traj_pool_path, llm_client, num_workers=se_config.get("num_workers"))
        traj_pool_manager.initialize_pool()
        logger.info(f"è½¨è¿¹æ± åˆå§‹åŒ–: {traj_pool_path}")
        print(f"ğŸŠ è½¨è¿¹æ± : {traj_pool_path}")

        print("\nğŸ“Š é…ç½®æ¦‚è§ˆ:")
        print(f"  åŸºç¡€é…ç½®: {se_config['base_config']}")
        print(f"  æ¨¡å‹: {se_config['model']['name']}")
        print(f"  å®ä¾‹ç›®å½•: {se_config['instances']['instances_dir']}")
        print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  è¿­ä»£æ¬¡æ•°: {len(se_config['strategy']['iterations'])}")

        # æ‰§è¡Œç­–ç•¥ä¸­çš„æ¯ä¸ªè¿­ä»£
        iterations = se_config["strategy"]["iterations"]
        for i, iteration in enumerate(iterations, 1):
            logger.info(f"å¼€å§‹ç¬¬{i}æ¬¡PerfAgentè¿­ä»£")
            print(f"\n=== ç¬¬{i}æ¬¡PerfAgentè¿­ä»£è°ƒç”¨ ===")

            iteration_output_dir = f"{output_dir}/iteration_{i}"

            # æ„å»º PerfAgent è¿­ä»£å‚æ•°ï¼ˆä¿æŒä¸ SE çš„ç»“æ„å…¼å®¹ï¼‰
            iteration_params = {
                "perf_base_config": iteration.get("perf_base_config"),  # å¯é€‰ï¼šæŒ‡å®š PerfAgent çš„åŸºç¡€é…ç½®
                "operator": iteration.get("operator"),  # å¯é€‰ï¼šæŒ‡å®šç®—å­
                "model": se_config.get("model", {}),
                "instances_dir": se_config.get("instances", {}).get("instances_dir", ""),
                "output_dir": iteration_output_dir,
                "max_iterations": se_config.get("max_iterations", 10),
                "num_workers": se_config.get("num_workers", 1),
            }

            # å¤„ç†operatorè¿”å›çš„é¢å¤–å‚æ•°
            operator_name = iteration.get("operator")
            if operator_name:
                print(f"ğŸ”§ è°ƒç”¨ç®—å­: {operator_name}")
                logger.info(f"æ‰§è¡Œç®—å­: {operator_name}")

                # è°ƒç”¨operatorå¤„ç†ï¼ˆä¼ é€’workspace_dirè€Œä¸æ˜¯iteration_output_dirï¼‰
                operator_result = call_operator(operator_name, output_dir, i, se_config, logger)
                if operator_result:
                    iteration_params["operator_params"] = operator_result
                    print(f"âœ… Operator {operator_name} æ‰§è¡ŒæˆåŠŸ")
                    print(f"ğŸ“‹ ç”Ÿæˆå‚æ•°: {list(operator_result.keys())}")
                    # ä¸´æ—¶é…ç½®åœ¨ call_perfagent ä¸­ç”Ÿæˆä¸æ¸…ç†ï¼Œæ— éœ€è¿™é‡Œå¤„ç†
                else:
                    print(f"âš ï¸  Operator {operator_name} æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œä½†ä¸ä½¿ç”¨å¢å¼º")
                    logger.warning(f"Operator {operator_name} æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œä½†ä¸ä½¿ç”¨å¢å¼º")
            else:
                print("ğŸ”„ æ— ç®—å­å¤„ç†")
                logger.debug(f"ç¬¬{i}æ¬¡è¿­ä»£æ— ç®—å­å¤„ç†")

            logger.debug(f"ç¬¬{i}æ¬¡PerfAgentè¿­ä»£å‚æ•°: {json.dumps(iteration_params, ensure_ascii=False)}")
            print(f"ä½¿ç”¨é…ç½®: {iteration.get('perf_base_config', 'None')}")
            print(f"ç®—å­: {iteration.get('operator', 'None')}")
            print(f"è¾“å‡ºç›®å½•: {iteration_output_dir}")

            # æ‰§è¡Œ PerfAgent
            if args.mode == "execute":
                logger.info(f"ç›´æ¥æ‰§è¡Œæ¨¡å¼ï¼šç¬¬{i}æ¬¡PerfAgentè¿­ä»£")
                result = call_perfagent(iteration_params, logger, dry_run=False)
                print(f"æ‰§è¡Œç»“æœ: {result['status']}")

                # æˆåŠŸåˆ™ç”Ÿæˆ.traå¹¶æ›´æ–° traj.pool
                # .tra ç›´æ¥ä½¿ç”¨ history ç”Ÿæˆ
                # traj.pool è½¨è¿¹æ€»ç»“é€šè¿‡ LLM Summary ç”Ÿæˆ
                if result.get("status") == "success":
                    logger.info(f"å¼€å§‹ä¸ºç¬¬{i}æ¬¡è¿­ä»£ç”Ÿæˆ.traæ–‡ä»¶")
                    try:
                        processor = TrajectoryProcessor()
                        iteration_dir = Path(iteration_output_dir)

                        # å¤„ç†å½“å‰è¿­ä»£ç›®å½•ä¸‹çš„æ‰€æœ‰å®ä¾‹
                        tra_stats = processor.process_iteration_directory(iteration_dir)
                        if tra_stats and tra_stats.get("total_tra_files", 0) > 0:
                            logger.info(
                                f"ç¬¬{i}æ¬¡PerfAgentè¿­ä»£.traæ–‡ä»¶ç”Ÿæˆå®Œæˆ: "
                                f"{tra_stats['total_tra_files']}ä¸ªæ–‡ä»¶, ~{tra_stats['total_tokens']}tokens"
                            )
                            print(f"ğŸ“ ç”Ÿæˆäº† {tra_stats['total_tra_files']} ä¸ª.traæ–‡ä»¶")

                            # æ›´æ–°è½¨è¿¹æ± 
                            try:
                                extractor = TrajExtractor()
                                instance_data_list = extractor.extract_instance_data(iteration_dir)
                                if instance_data_list:
                                    # äº¤ç”± TrajPoolManager å¹¶è¡Œç”Ÿæˆå¹¶æ‰¹é‡å†™å…¥ï¼Œé¿å…å¹¶å‘å†™æ–‡ä»¶
                                    processed_count = traj_pool_manager.summarize_and_add_iteration_batch(
                                        instance_data_list, iteration=i, num_workers=se_config.get("num_workers")
                                    )
                                    logger.info(f"æˆåŠŸæå–å¹¶å¤„ç†äº† {processed_count} ä¸ªå®ä¾‹")
                                else:
                                    logger.warning(f"ç¬¬{i}æ¬¡è¿­ä»£æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å®ä¾‹æ•°æ®")
                                    print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å®ä¾‹æ•°æ®")

                                pool_stats = traj_pool_manager.get_pool_stats()
                                logger.info(
                                    f"è½¨è¿¹æ± æ›´æ–°å®Œæˆ: {pool_stats['total_instances']}å®ä¾‹, {pool_stats['total_iterations']}æ€»è¿­ä»£"
                                )
                                print(
                                    f"ğŸŠ è½¨è¿¹æ± æ›´æ–°: {pool_stats['total_instances']}å®ä¾‹, {pool_stats['total_iterations']}æ€»è¿­ä»£"
                                )
                            except Exception as pool_error:
                                logger.error(f"ç¬¬{i}æ¬¡è¿­ä»£è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {pool_error}")
                                print(f"âš ï¸ è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {pool_error}")
                        else:
                            logger.warning(f"ç¬¬{i}æ¬¡è¿­ä»£æœªç”Ÿæˆ.traæ–‡ä»¶")
                            print("âš ï¸ æœªç”Ÿæˆ.traæ–‡ä»¶ï¼ˆå¯èƒ½æ²¡æœ‰æœ‰æ•ˆè½¨è¿¹ï¼‰")
                    except Exception as tra_error:
                        logger.error(f"ç¬¬{i}æ¬¡è¿­ä»£ç”Ÿæˆ.traæ–‡ä»¶å¤±è´¥: {tra_error}")
                        print(f"âš ï¸ .traæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {tra_error}")

            else:
                logger.info(f"æ¼”ç¤ºæ¨¡å¼ï¼šç¬¬{i}æ¬¡PerfAgentè¿­ä»£")
                result = call_perfagent(iteration_params, logger, dry_run=True)
                print(f"æ¼”ç¤ºç»“æœ: {result['status']}")
                print("ğŸ“ æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡.traæ–‡ä»¶ç”Ÿæˆä¸è½¨è¿¹æ± æ›´æ–°")

            if result.get("status") == "failed":
                logger.error(f"ç¬¬{i}æ¬¡PerfAgentè¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œåœæ­¢åç»­è¿­ä»£")
                break

        logger.info("æ‰€æœ‰PerfAgentè¿­ä»£å‡†å¤‡å®Œæˆ")

        print("\nğŸ¯ æ‰§è¡Œæ€»ç»“:")
        print(f"  âœ… è§£æ{len(iterations)}ä¸ªè¿­ä»£é…ç½®")
        print(f"  âœ… æ—¶é—´æˆ³: {timestamp}")
        print(f"  âœ… æ—¥å¿—æ–‡ä»¶: {log_file}")
        print(f"  ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        try:
            final_pool_stats = traj_pool_manager.get_pool_stats()
            print(
                f"  ğŸŠ è½¨è¿¹æ± : {final_pool_stats['total_instances']}å®ä¾‹, {final_pool_stats['total_iterations']}æ€»è¿­ä»£"
            )
            print(f"  ğŸŠ è½¨è¿¹æ± æ–‡ä»¶: {traj_pool_path}")
        except Exception:
            pass

        logger.info("SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œå®Œæˆ")

        logger.info("å¼€å§‹é€‰æ‹©æ¯ä¸ªä»»åŠ¡çš„æœ€ä¼˜è§£")
        try:
            # 1) æ±‡æ€»æ‰€æœ‰è¿­ä»£çš„ preds.json åˆ°è¿è¡Œæ ¹ç›®å½• preds.jsonï¼ˆå« iteration å­—æ®µï¼‰
            root_output_dir = Path(output_dir)
            agg_preds_path = aggregate_all_iterations_preds(root_output_dir, logger)

            # 2) ä»æ±‡æ€» preds.json é‡Œä¸ºæ¯ä¸ªå®ä¾‹é€‰å– runtime æœ€å°çš„è§£ï¼Œç”Ÿæˆ final.json
            if agg_preds_path and Path(agg_preds_path).exists():
                write_final_json_from_preds(Path(agg_preds_path), root_output_dir, logger)
            else:
                logger.warning("æœªæ‰¾åˆ°æ±‡æ€» preds.jsonï¼Œè·³è¿‡ final.json ç”Ÿæˆ")
        except Exception as sel_err:
            logger.warning(f"é€‰æ‹©æœ€ä¼˜è§£å¤±è´¥: {sel_err}")

    except Exception as e:
        if "logger" in locals():
            logger.error(f"è¿è¡Œå‡ºé”™: {e}", exc_info=True)
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
