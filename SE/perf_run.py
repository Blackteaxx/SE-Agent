#!/usr/bin/env python3
"""
PerfAgent é›†æˆæ‰§è¡Œè„šæœ¬
æ¨¡ä»¿ SE/basic_run.py çš„ç»“æ„ï¼Œåœ¨ SE æ¡†æ¶ä¸­é©±åŠ¨ perfagent çš„å•/å¤šå®ä¾‹æ€§èƒ½ä¼˜åŒ–ã€‚
"""

import argparse
import json
import os
import subprocess
import sys
import tempfile
import math
from datetime import datetime
from pathlib import Path
from typing import Optional

import yaml

# æ·»åŠ SEç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥SEæ—¥å¿—ç³»ç»Ÿ
from core.utils.se_logger import get_se_logger, setup_se_logging
from core.utils.traj_extractor import TrajExtractor
from core.utils.traj_pool_manager import TrajPoolManager
from core.utils.trajectory_processor import TrajectoryProcessor

# å¯¼å…¥operatorç³»ç»Ÿ
from operators import create_operator, list_operators


def call_operator(operator_name, workspace_dir, current_iteration, se_config, logger):
    """
    è°ƒç”¨æŒ‡å®šçš„operatorå¤„ç†

    Args:
        operator_name: operatoråç§°
        workspace_dir: å·¥ä½œç©ºé—´æ ¹ç›®å½• (ä¸å¸¦è¿­ä»£å·)
        current_iteration: å½“å‰è¿­ä»£å·
        se_config: SEé…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        operatorè¿”å›çš„å‚æ•°å­—å…¸ (å¦‚ {'instance_templates_dir': 'path'}) æˆ– Noneè¡¨ç¤ºå¤±è´¥
    """
    try:
        logger.info(f"å¼€å§‹è°ƒç”¨operator: {operator_name}")

        # åŠ¨æ€åˆ›å»ºoperatorå®ä¾‹
        operator = create_operator(operator_name, se_config)
        if not operator:
            logger.error(f"æ— æ³•åˆ›å»ºoperatorå®ä¾‹: {operator_name}")
            return None

        logger.info(f"æˆåŠŸåˆ›å»ºoperatorå®ä¾‹: {operator.__class__.__name__}")

        # è°ƒç”¨operator.process()æ–¹æ³•
        result = operator.process(
            workspace_dir=workspace_dir,
            current_iteration=current_iteration,
            num_workers=se_config.get("num_workers", 1),
        )

        if result:
            logger.info(f"Operator {operator_name} æ‰§è¡ŒæˆåŠŸï¼Œè¿”å›: {list(result.keys())}")
            return result
        else:
            logger.warning(f"Operator {operator_name} æ‰§è¡ŒæˆåŠŸä½†è¿”å›ç©ºç»“æœ")
            return None

    except Exception as e:
        logger.error(f"Operator {operator_name} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return None

def write_iteration_preds(base_dir: Path, logger) -> Optional[Path]:
    """
    èšåˆå½“å‰è¿­ä»£å„å®ä¾‹çš„ç»“æœï¼Œç”Ÿæˆ preds.jsonã€‚

    - passedï¼šç›´æ¥ä¾æ® final_performance æ˜¯å¦ä¸º infï¼ˆæˆ–å­—ç¬¦ä¸²è¡¨ç¤ºçš„æ— ç©·ï¼‰åˆ¤æ–­ã€‚
    - runtimeï¼šè¾“å‡ºæœ€ç»ˆæ€§èƒ½å€¼ï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œå¦åˆ™å›é€€åˆ°åˆå§‹è¯„ä¼°çš„ä¿®å‰ªå‡å€¼ã€‚
    - codeï¼šä¼˜å…ˆä½¿ç”¨ optimized_codeï¼Œå›é€€åˆ° initial_codeã€‚

    è¿”å›ç”Ÿæˆçš„ preds.json è·¯å¾„ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    preds = {}
    try:
        for inst_dir in base_dir.iterdir():
            if not inst_dir.is_dir():
                continue
            res_file = inst_dir / "result.json"
            if not res_file.exists():
                continue
            try:
                with open(res_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
            except Exception:
                continue

            instance_id = data.get("instance_id", inst_dir.name)
            code = data.get("optimized_code", "")

            # è¯»å–æœ€ç»ˆæ€§èƒ½å€¼å¹¶ç”¨äº passed åˆ¤æ–­
            final_perf = data.get("final_performance")

            # runtimeï¼šä¼˜å…ˆ final_performanceï¼Œå¦åˆ™ initial trimmed_mean
            runtime = final_perf

            # passedï¼šfinal_performance ä¸º inf åˆ™ Falseï¼Œå¦åˆ™ True
            passed = not math.isinf(float(final_perf)) if final_perf is not None else False
            preds[str(instance_id)] = {
                "code": code,
                "passed": passed,
                "runtime": runtime,
            }

        preds_path = base_dir / "preds.json"
        with open(preds_path, "w", encoding="utf-8") as pf:
            json.dump(preds, pf, indent=2, ensure_ascii=False)
        print(f"ğŸ“ å·²ç”Ÿæˆ preds.json: {preds_path}")
        logger.info(f"å·²ç”Ÿæˆ preds.json: {preds_path}")
        return preds_path
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ preds.json å¤±è´¥: {e}")
        return None


def aggregate_all_iterations_preds(root_output_dir: Path, logger) -> Optional[Path]:
    """
    æ±‡æ€»æ‰€æœ‰ iteration_* ç›®å½•ä¸‹çš„ preds.jsonï¼Œè¿‡æ»¤æœªé€šè¿‡é¡¹ï¼Œæ·»åŠ è¿­ä»£å·å¹¶å†™å…¥è¿è¡Œæ ¹ç›®å½•çš„ preds.jsonã€‚

    è¾“å‡ºç»“æ„ç¤ºä¾‹ï¼š
    {
      "inst1": [
        {"iteration": 1, "code": "...", "runtime": 1.23},
        {"iteration": 2, "code": "...", "runtime": 1.11}
      ],
      "inst2": [
        {"iteration": 2, "code": "...", "runtime": 0.98}
      ]
    }
    """
    aggregated: dict[str, list[dict]] = {}
    try:
        for iter_dir in sorted(root_output_dir.glob("iteration_*")):
            if not iter_dir.is_dir():
                continue
            # è§£æè¿­ä»£å·
            try:
                iter_num = int(iter_dir.name.split("_")[-1])
            except Exception:
                iter_num = None

            preds_file = iter_dir / "preds.json"
            if not preds_file.exists():
                continue
            try:
                with open(preds_file, "r", encoding="utf-8") as pf:
                    preds = json.load(pf)
            except Exception:
                continue

            for instance_id, info in preds.items():
                try:
                    if not bool(info.get("passed", False)):
                        continue
                    code = info.get("code", "")
                    runtime = info.get("runtime")
                    entry = {"iteration": iter_num, "code": code, "runtime": runtime}
                    aggregated.setdefault(str(instance_id), []).append(entry)
                except Exception:
                    continue

        agg_path = root_output_dir / "preds.json"
        with open(agg_path, "w", encoding="utf-8") as f:
            json.dump(aggregated, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ æ±‡æ€» preds.json: {agg_path}")
        logger.info(f"æ±‡æ€» preds.json: {agg_path}")
        return agg_path
    except Exception as e:
        logger.warning(f"æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None


def write_final_json_from_preds(aggregated_preds_path: Path, root_output_dir: Path, logger) -> Optional[Path]:
    """
    ä»è¿è¡Œæ ¹ç›®å½•çš„ preds.jsonï¼ˆæ±‡æ€»ï¼‰é€‰æ‹©æ¯ä¸ªå®ä¾‹ runtime æœ€å°çš„è§£ï¼Œå†™å…¥ final.jsonã€‚

    æ–‡ä»¶ç»“æ„ï¼š
    {
      "instance_name": "code"
    }
    """
    try:
        with open(aggregated_preds_path, "r", encoding="utf-8") as f:
            aggregated = json.load(f)
    except Exception as e:
        logger.warning(f"è¯»å–æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None

    def to_float(rt):
        try:
            if rt is None:
                return float("inf")
            if isinstance(rt, (int, float)):
                return float(rt)
            if isinstance(rt, str):
                lowered = rt.strip().lower()
                if lowered in ("inf", "infinity", "nan"):
                    return float("inf")
                return float(rt)
            return float("inf")
        except Exception:
            return float("inf")

    final_map: dict[str, str] = {}
    try:
        for instance_id, entries in aggregated.items():
            if not isinstance(entries, list) or not entries:
                continue
            try:
                best = min(entries, key=lambda e: to_float(e.get("runtime")))
            except Exception:
                continue
            final_map[str(instance_id)] = best.get("code", "")

        final_path = root_output_dir / "final.json"
        with open(final_path, "w", encoding="utf-8") as f:
            json.dump(final_map, f, indent=2, ensure_ascii=False)
        print(f"ğŸ ç”Ÿæˆ final.json: {final_path}")
        logger.info(f"ç”Ÿæˆ final.json: {final_path}")
        return final_path
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ final.json å¤±è´¥: {e}")
        return None

def call_perfagent(iteration_params, logger, dry_run=False):
    """
    ç›´æ¥è°ƒç”¨ perfagent.run_batch çš„æ‰¹é‡æ‰§è¡Œæ¥å£ï¼Œè¿è¡Œæœ¬æ¬¡è¿­ä»£çš„å®ä¾‹ä¼˜åŒ–
    """
    base_config_path = iteration_params.get("perf_base_config")

    try:
        # ä½¿ç”¨åŸºç¡€é…ç½®æ–‡ä»¶ï¼Œä¸åˆ›å»ºä¸´æ—¶é…ç½®
        logger.debug(f"ä½¿ç”¨PerfAgentåŸºç¡€é…ç½®: {base_config_path}")
        if base_config_path:
            print(f"ğŸ“‹ ä½¿ç”¨åŸºç¡€é…ç½®æ–‡ä»¶: {base_config_path}")

        if dry_run:
            logger.warning("æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡PerfAgentå®é™…æ‰§è¡Œ")
            return {"status": "skipped", "reason": "dry_run"}

        # ç›®æ ‡è·¯å¾„å’Œå‘½ä»¤ï¼ˆæ‰¹é‡æ‰§è¡Œè„šæœ¬ï¼‰
        se_root = Path(__file__).parent
        project_root = se_root.parent

        # é€‰æ‹©å®ä¾‹ç›®å½•
        instances_dir = iteration_params.get("instances_dir")

        # åŸºç¡€ç›®å½•ï¼šä½¿ç”¨å½“å‰è¿­ä»£çš„è¾“å‡ºç›®å½•ï¼Œè®©æ¯ä¸ªå®ä¾‹åœ¨å…¶å­ç›®å½•ä¸‹ç”Ÿæˆæ—¥å¿—ä¸è½¨è¿¹
        base_dir = Path(iteration_params["output_dir"])
        
        # ä¼˜å…ˆä½¿ç”¨åŸºç¡€é…ç½®ï¼›å¦‚æœæä¾› instance_templates_dirï¼Œåˆ™äº¤ç”± run_batch åšæ¯ä»»åŠ¡åˆå¹¶
        # ç»„è£…å‘½ä»¤
        cmd = [
            sys.executable,
            "-m",
            "perfagent.run_batch",
            "--config",
            str(base_config_path),
            "--instances-dir",
            str(instances_dir),
            "--base-dir",
            str(base_dir),
            "--max-workers",
            str(iteration_params.get("num_workers", 1)),
        ]

        # è‹¥ operator è¿”å› instance_templates_dirï¼Œåˆ™ä¼ ç»™ run_batch åšæ¯ä»»åŠ¡åˆå¹¶
        operator_params = iteration_params.get("operator_params", {}) or {}
        itd = operator_params.get("instance_templates_dir")
        if itd:
            cmd.extend(["--instance-templates-dir", str(itd)])

        print(f"ğŸš€ æ‰§è¡ŒPerfAgentæ‰¹é‡å‘½ä»¤: {' '.join(cmd)}")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {project_root}")
        print("=" * 60)

        result = subprocess.run(cmd, cwd=str(project_root), text=True)

        print("=" * 60)
        if result.returncode == 0:
            logger.info("PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡ŒæˆåŠŸ")
            print("âœ… PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡ŒæˆåŠŸ")

            preds_path = write_iteration_preds(base_dir, logger)
            return {
                "status": "success",
                "summary": "success",
                "base_dir": str(base_dir),
                "preds_file": str(preds_path) if preds_path else None,
            }
        else:
            logger.error(f"PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"âŒ PerfAgentæ‰¹é‡è¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return {"status": "failed", "returncode": result.returncode}

    except Exception as e:
        logger.error(f"è°ƒç”¨PerfAgentæ—¶å‡ºé”™: {e}", exc_info=True)
        return {"status": "error", "exception": str(e)}
    finally:
        # æ— ä¸´æ—¶é…ç½®éœ€è¦æ¸…ç†
        pass


def _get_nested(data: dict, path: str):
    cur = data
    for key in path.split("."):
        if not isinstance(cur, dict):
            return None
        cur = cur.get(key)
        if cur is None:
            return None
    return cur


def _normalize_text_or_list(val) -> str:
    if val is None:
        return ""
    if isinstance(val, str):
        return val.strip()
    if isinstance(val, list):
        # ä»¥é¡¹ç›®ç¬¦å·çš„å½¢å¼ç»„åˆåˆ—è¡¨å†…å®¹
        items = []
        for v in val:
            if isinstance(v, str):
                t = v.strip()
            else:
                t = str(v).strip()
            if t:
                items.append(f"- {t}")
        return "\n".join(items)
    # å…¶ä»–ç±»å‹å›é€€ä¸ºå­—ç¬¦ä¸²
    try:
        return str(val).strip()
    except Exception:
        return ""


def build_additional_requirements_from_dir(templates_dir: Path, logger) -> str:
    """ä» YAML æ¨¡æ¿ç›®å½•æ„å»º additional_requirements æ–‡æœ¬ã€‚

    æ”¯æŒçš„é”®ï¼ˆæŒ‰ä¼˜å…ˆçº§èšåˆï¼‰ï¼š
    - additional_requirements
    - templates.additional_requirements
    - agent.templates.additional_requirements
    - system_template_append
    - templates.system_template_append
    - agent.templates.system_template_append
    - system_template
    - templates.system_template
    - agent.templates.system_template
    """
    if not templates_dir or not Path(templates_dir).exists():
        return ""

    pieces = []
    try:
        yaml_files = list(Path(templates_dir).glob("*.y*ml"))
        for yf in yaml_files:
            try:
                with open(yf, "r", encoding="utf-8") as f:
                    data = yaml.safe_load(f) or {}
            except Exception as e:
                logger.warning(f"è¯»å–æ¨¡æ¿ {yf} å¤±è´¥: {e}")
                continue

            key_paths = [
                "additional_requirements",
                "templates.additional_requirements",
                "agent.templates.additional_requirements",
                "system_template_append",
                "templates.system_template_append",
                "agent.templates.system_template_append",
                "system_template",
                "templates.system_template",
                "agent.templates.system_template",
            ]

            for kp in key_paths:
                val = _get_nested(data, kp)
                text = _normalize_text_or_list(val)
                if text:
                    pieces.append(text)
    except Exception as e:
        logger.warning(f"æ‰«ææ¨¡æ¿ç›®å½•å¤±è´¥: {e}")

    # åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æœ¬å—
    merged = "\n\n".join(pieces).strip()
    return merged


def create_temp_perf_config(iteration_params, base_config_path, logger) -> Optional[Path]:
    """åˆ›å»ºä¸´æ—¶ PerfAgent é…ç½®ï¼Œå°†ç®—å­ç”Ÿæˆçš„ instance_templates_dir åˆå¹¶ä¸º prompts.additional_requirementsã€‚

    - è¯»å–åŸºç¡€ PerfAgent é…ç½® YAML
    - ä» operator_params.instance_templates_dir æ„å»º additional_requirements æ–‡æœ¬
    - è‹¥åŸºç¡€é…ç½®å·²æœ‰ prompts.additional_requirementsï¼Œåˆ™è¿›è¡Œåˆå¹¶æ‹¼æ¥
    - ç§»é™¤ prompts.instance_templates_dir é¿å…æ­§ä¹‰
    - å†™å‡ºä¸´æ—¶ YAML æ–‡ä»¶å¹¶è¿”å›è·¯å¾„ï¼›è‹¥æ— å¯æ³¨å…¥å†…å®¹åˆ™è¿”å› None
    """
    if not base_config_path:
        return None
    try:
        with open(base_config_path, "r", encoding="utf-8") as f:
            base_cfg = yaml.safe_load(f) or {}
    except Exception as e:
        logger.warning(f"è¯»å–åŸºç¡€PerfAgenté…ç½®å¤±è´¥: {e}")
        return None

    operator_params = iteration_params.get("operator_params", {}) or {}

    # 1) ä¼˜å…ˆä»ç®—å­è¾“å‡ºç›®å½•æ„å»º
    add_texts = []
    itd = operator_params.get("instance_templates_dir")
    if itd:
        try:
            txt = build_additional_requirements_from_dir(Path(itd), logger)
            if txt:
                add_texts.append(txt)
        except Exception as e:
            logger.warning(f"è§£æç®—å­æ¨¡æ¿ç›®å½•å¤±è´¥: {e}")

    # 2) ç›´æ¥ä»ç®—å­è¿”å› additional_requirementsï¼ˆè‹¥æœ‰ï¼‰
    op_additional = operator_params.get("additional_requirements")
    if op_additional:
        txt = _normalize_text_or_list(op_additional)
        if txt:
            add_texts.append(txt)

    # 3) åŸºç¡€é…ç½®ä¸­å·²æœ‰çš„ additional_requirementsï¼ˆè‹¥æœ‰ï¼‰ï¼Œä¹Ÿå¹¶å…¥
    existing_base = None
    try:
        existing_base = base_cfg.get("prompts", {}).get("additional_requirements")
    except Exception:
        existing_base = None
    if existing_base:
        txt = _normalize_text_or_list(existing_base)
        if txt:
            add_texts.append(txt)

    # è‹¥æ²¡æœ‰ä»»ä½•é™„åŠ å†…å®¹ï¼Œä¸ç”Ÿæˆä¸´æ—¶é…ç½®
    merged_text = "\n\n".join([t for t in add_texts if t]).strip()
    if not merged_text:
        return None

    # æ³¨å…¥åˆ° prompts.additional_requirementsï¼Œå¹¶ç§»é™¤æ—§å­—æ®µ
    if "prompts" not in base_cfg or base_cfg.get("prompts") is None:
        base_cfg["prompts"] = {}
    base_cfg["prompts"]["additional_requirements"] = merged_text
    if "instance_templates_dir" in base_cfg["prompts"]:
        base_cfg["prompts"].pop("instance_templates_dir", None)

    # å†™å‡ºä¸´æ—¶é…ç½®
    fd, temp_path = tempfile.mkstemp(suffix=".yaml", prefix="perfagent_iteration_")
    try:
        with os.fdopen(fd, "w", encoding="utf-8") as tmp:
            yaml.safe_dump(base_cfg, tmp, allow_unicode=True, sort_keys=False)
    except Exception as e:
        try:
            os.close(fd)
        except Exception:
            pass
        try:
            os.unlink(temp_path)
        except Exception:
            pass
        logger.warning(f"å†™å‡ºä¸´æ—¶PerfAgenté…ç½®å¤±è´¥: {e}")
        return None

    return Path(temp_path)

def generate_per_task_configs(base_config_path: Path, instances_dir: Path, output_dir: Path, operator_result: dict, logger) -> Optional[Path]:
    """åŸºäºåŸºç¡€é…ç½®ç”Ÿæˆæ¯ä»»åŠ¡é…ç½®ï¼Œæ³¨å…¥ additional_requirementsã€‚

    - è‹¥ operator_result æä¾› instance_templates_dirï¼Œåˆ™è¯»å–å¹¶æ„å»ºé™„åŠ è¦æ±‚æ–‡æœ¬ã€‚
    - å°†è¯¥æ–‡æœ¬å†™å…¥ prompts.additional_requirements å­—æ®µã€‚
    - ä¸ºæ¯ä¸ªå®ä¾‹ç”Ÿæˆä¸€ä¸ª <task_name>.yaml é…ç½®æ–‡ä»¶ã€‚
    """
    if not base_config_path or not Path(base_config_path).exists():
        logger.warning("æœªæä¾›æœ‰æ•ˆçš„ PerfAgent åŸºç¡€é…ç½®ï¼Œè·³è¿‡æ¯ä»»åŠ¡é…ç½®ç”Ÿæˆ")
        return None

    instances_path = Path(instances_dir)
    if not instances_path.exists():
        logger.warning("å®ä¾‹ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¯ä»»åŠ¡é…ç½®ç”Ÿæˆ")
        return None

    # è§£æ operator ç»“æœ
    add_req_text = ""
    try:
        if operator_result:
            itd = operator_result.get("instance_templates_dir")
            if itd:
                add_req_text = build_additional_requirements_from_dir(Path(itd), logger)
            else:
                # å…è®¸ç®—å­ç›´æ¥è¿”å› additional_requirements
                add_req_text = _normalize_text_or_list(operator_result.get("additional_requirements"))
    except Exception as e:
        logger.warning(f"å¤„ç† operator ç»“æœå¤±è´¥: {e}")

    if not add_req_text:
        # æ— é™„åŠ è¦æ±‚åˆ™ä¸ç”Ÿæˆæ¯ä»»åŠ¡é…ç½®
        return None

    per_task_dir = Path(output_dir) / "per_task_configs"
    per_task_dir.mkdir(parents=True, exist_ok=True)

    # è¯»å–åŸºç¡€é…ç½®ä¸€æ¬¡
    try:
        with open(base_config_path, "r", encoding="utf-8") as f:
            base_cfg = yaml.safe_load(f) or {}
    except Exception as e:
        logger.error(f"è¯»å–åŸºç¡€é…ç½®å¤±è´¥: {e}")
        return None

    # æ³¨å…¥ prompts.additional_requirements
    if "prompts" not in base_cfg or base_cfg.get("prompts") is None:
        base_cfg["prompts"] = {}
    base_cfg["prompts"]["additional_requirements"] = add_req_text
    # ç§»é™¤æ—§å­—æ®µä»¥é¿å…æ­§ä¹‰ï¼ˆå¯é€‰ï¼‰
    if "instance_templates_dir" in base_cfg["prompts"]:
        base_cfg["prompts"].pop("instance_templates_dir", None)

    # ä¸ºæ¯ä¸ªå®ä¾‹å†™å‡ºä¸“å±é…ç½®
    for inst_file in instances_path.glob("*.json"):
        task_name = inst_file.stem
        cfg_path = per_task_dir / f"{task_name}.yaml"
        try:
            with open(cfg_path, "w", encoding="utf-8") as f:
                yaml.safe_dump(base_cfg, f, allow_unicode=True, sort_keys=False)
        except Exception as e:
            logger.warning(f"å†™å‡ºæ¯ä»»åŠ¡é…ç½®å¤±è´¥ {cfg_path}: {e}")

    return per_task_dir


def main():
    """ä¸»å‡½æ•°ï¼šç­–ç•¥é©±åŠ¨çš„ PerfAgent å¤šè¿­ä»£æ‰§è¡Œ"""

    parser = argparse.ArgumentParser(description="SE æ¡†æ¶ PerfAgent å¤šè¿­ä»£æ‰§è¡Œè„šæœ¬")
    parser.add_argument("--config", default="SE/configs/se_configs/dpsk.yaml", help="SE é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--mode", choices=["demo", "execute"], default="execute", help="è¿è¡Œæ¨¡å¼: demo=æ¼”ç¤ºæ¨¡å¼, execute=ç›´æ¥æ‰§è¡Œ"
    )
    args = parser.parse_args()

    print("=== SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œ ===")
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")

    try:
        # è¯»å– SE é…ç½®æ–‡ä»¶
        with open(args.config, "r", encoding="utf-8") as f:
            se_config = yaml.safe_load(f)

        # ç”Ÿæˆ timestamp å¹¶æ›¿æ¢è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = se_config["output_dir"].replace("{timestamp}", timestamp)

        # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
        log_file = setup_se_logging(output_dir)
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")

        logger = get_se_logger("perf_run", emoji="âš¡")
        logger.info("SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œå¯åŠ¨")
        logger.debug(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        logger.info(f"ç”Ÿæˆtimestamp: {timestamp}")
        logger.info(f"å®é™…è¾“å‡ºç›®å½•: {output_dir}")

        # åˆå§‹åŒ–è½¨è¿¹æ± ç®¡ç†å™¨
        traj_pool_path = os.path.join(output_dir, "traj.pool")

        # åˆ›å»ºLLMå®¢æˆ·ç«¯ç”¨äºè½¨è¿¹æ€»ç»“
        llm_client = None
        try:
            from core.utils.llm_client import LLMClient

            # ä½¿ç”¨operator_modelsé…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¸»æ¨¡å‹é…ç½®
            llm_client = LLMClient.from_se_config(se_config, use_operator_model=True)
            logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {llm_client.config['name']}")
        except Exception as e:
            logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ€»ç»“: {e}")

        traj_pool_manager = TrajPoolManager(traj_pool_path, llm_client)
        traj_pool_manager.initialize_pool()
        logger.info(f"è½¨è¿¹æ± åˆå§‹åŒ–: {traj_pool_path}")
        print(f"ğŸŠ è½¨è¿¹æ± : {traj_pool_path}")

        print(f"\nğŸ“Š é…ç½®æ¦‚è§ˆ:")
        print(f"  åŸºç¡€é…ç½®: {se_config['base_config']}")
        print(f"  æ¨¡å‹: {se_config['model']['name']}")
        print(f"  å®ä¾‹ç›®å½•: {se_config['instances']['instances_dir']}")
        print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  è¿­ä»£æ¬¡æ•°: {len(se_config['strategy']['iterations'])}")

        # æ‰§è¡Œç­–ç•¥ä¸­çš„æ¯ä¸ªè¿­ä»£
        iterations = se_config["strategy"]["iterations"]
        for i, iteration in enumerate(iterations, 1):
            logger.info(f"å¼€å§‹ç¬¬{i}æ¬¡PerfAgentè¿­ä»£")
            print(f"\n=== ç¬¬{i}æ¬¡PerfAgentè¿­ä»£è°ƒç”¨ ===")

            iteration_output_dir = f"{output_dir}/iteration_{i}"

            # æ„å»º PerfAgent è¿­ä»£å‚æ•°ï¼ˆä¿æŒä¸ SE çš„ç»“æ„å…¼å®¹ï¼‰
            iteration_params = {
                "perf_base_config": iteration.get("perf_base_config"),  # å¯é€‰ï¼šæŒ‡å®š PerfAgent çš„åŸºç¡€é…ç½®
                "operator": iteration.get("operator"),  # å¯é€‰ï¼šæŒ‡å®šç®—å­
                "model": se_config.get("model", {}),
                "instances_dir": se_config.get("instances", {}).get("instances_dir", ""),
                "output_dir": iteration_output_dir,
                "max_iterations": se_config.get("max_iterations", 10),
                "num_workers": se_config.get("num_workers", 1),
            }

            # å¤„ç†operatorè¿”å›çš„é¢å¤–å‚æ•°
            operator_name = iteration.get("operator")
            if operator_name:
                print(f"ğŸ”§ è°ƒç”¨ç®—å­: {operator_name}")
                logger.info(f"æ‰§è¡Œç®—å­: {operator_name}")

                # è°ƒç”¨operatorå¤„ç†ï¼ˆä¼ é€’workspace_dirè€Œä¸æ˜¯iteration_output_dirï¼‰
                operator_result = call_operator(operator_name, output_dir, i, se_config, logger)
                if operator_result:
                    iteration_params["operator_params"] = operator_result
                    print(f"âœ… Operator {operator_name} æ‰§è¡ŒæˆåŠŸ")
                    print(f"ğŸ“‹ ç”Ÿæˆå‚æ•°: {list(operator_result.keys())}")
                    # ä¸´æ—¶é…ç½®åœ¨ call_perfagent ä¸­ç”Ÿæˆä¸æ¸…ç†ï¼Œæ— éœ€è¿™é‡Œå¤„ç†
                else:
                    print(f"âš ï¸  Operator {operator_name} æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œä½†ä¸ä½¿ç”¨å¢å¼º")
                    logger.warning(f"Operator {operator_name} æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œä½†ä¸ä½¿ç”¨å¢å¼º")
            else:
                print(f"ğŸ”„ æ— ç®—å­å¤„ç†")
                logger.debug(f"ç¬¬{i}æ¬¡è¿­ä»£æ— ç®—å­å¤„ç†")

            logger.debug(f"ç¬¬{i}æ¬¡PerfAgentè¿­ä»£å‚æ•°: {json.dumps(iteration_params, ensure_ascii=False)}")
            print(f"ä½¿ç”¨é…ç½®: {iteration.get('perf_base_config', 'None')}")
            print(f"ç®—å­: {iteration.get('operator', 'None')}")
            print(f"è¾“å‡ºç›®å½•: {iteration_output_dir}")

            # æ‰§è¡Œ PerfAgent
            if args.mode == "execute":
                logger.info(f"ç›´æ¥æ‰§è¡Œæ¨¡å¼ï¼šç¬¬{i}æ¬¡PerfAgentè¿­ä»£")
                result = call_perfagent(iteration_params, logger, dry_run=False)
                print(f"æ‰§è¡Œç»“æœ: {result['status']}")

                # æˆåŠŸåˆ™ç”Ÿæˆ.traå¹¶æ›´æ–°è½¨è¿¹æ± 
                if result.get("status") == "success":
                    logger.info(f"å¼€å§‹ä¸ºç¬¬{i}æ¬¡è¿­ä»£ç”Ÿæˆ.traæ–‡ä»¶")
                    # ç”Ÿæˆ .tra æ–‡ä»¶
                    try:
                        processor = TrajectoryProcessor()
                        iteration_dir = Path(iteration_output_dir)

                        # å¤„ç†å½“å‰è¿­ä»£ç›®å½•ä¸‹çš„æ‰€æœ‰å®ä¾‹
                        tra_stats = processor.process_iteration_directory(iteration_dir)
                        if tra_stats and tra_stats.get("total_tra_files", 0) > 0:
                            logger.info(
                                f"ç¬¬{i}æ¬¡PerfAgentè¿­ä»£.traæ–‡ä»¶ç”Ÿæˆå®Œæˆ: "
                                f"{tra_stats['total_tra_files']}ä¸ªæ–‡ä»¶, ~{tra_stats['total_tokens']}tokens"
                            )
                            print(f"ğŸ“ ç”Ÿæˆäº† {tra_stats['total_tra_files']} ä¸ª.traæ–‡ä»¶")

                            # æ›´æ–°è½¨è¿¹æ± 
                            try:
                                extractor = TrajExtractor()
                                instance_data_list = extractor.extract_instance_data(iteration_dir)
                                if instance_data_list:
                                    for (
                                        instance_name,
                                        problem_description,
                                        trajectory_content,
                                        patch_content,
                                    ) in instance_data_list:
                                        traj_pool_manager.add_iteration_summary(
                                            instance_name=instance_name,
                                            iteration=i,
                                            trajectory_content=trajectory_content,
                                            patch_content=patch_content,
                                            problem_description=problem_description or None,
                                        )
                                    logger.info(f"æˆåŠŸæå–å¹¶å¤„ç†äº† {len(instance_data_list)} ä¸ªå®ä¾‹")
                                else:
                                    logger.warning(f"ç¬¬{i}æ¬¡è¿­ä»£æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å®ä¾‹æ•°æ®")
                                    print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å®ä¾‹æ•°æ®")

                                pool_stats = traj_pool_manager.get_pool_stats()
                                logger.info(
                                    f"è½¨è¿¹æ± æ›´æ–°å®Œæˆ: {pool_stats['total_instances']}å®ä¾‹, {pool_stats['total_iterations']}æ€»è¿­ä»£"
                                )
                                print(
                                    f"ğŸŠ è½¨è¿¹æ± æ›´æ–°: {pool_stats['total_instances']}å®ä¾‹, {pool_stats['total_iterations']}æ€»è¿­ä»£"
                                )
                            except Exception as pool_error:
                                logger.error(f"ç¬¬{i}æ¬¡è¿­ä»£è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {pool_error}")
                                print(f"âš ï¸ è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {pool_error}")
                        else:
                            logger.warning(f"ç¬¬{i}æ¬¡è¿­ä»£æœªç”Ÿæˆ.traæ–‡ä»¶")
                            print("âš ï¸ æœªç”Ÿæˆ.traæ–‡ä»¶ï¼ˆå¯èƒ½æ²¡æœ‰æœ‰æ•ˆè½¨è¿¹ï¼‰")
                    except Exception as tra_error:
                        logger.error(f"ç¬¬{i}æ¬¡è¿­ä»£ç”Ÿæˆ.traæ–‡ä»¶å¤±è´¥: {tra_error}")
                        print(f"âš ï¸ .traæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {tra_error}")
            else:
                logger.info(f"æ¼”ç¤ºæ¨¡å¼ï¼šç¬¬{i}æ¬¡PerfAgentè¿­ä»£")
                result = call_perfagent(iteration_params, logger, dry_run=True)
                print(f"æ¼”ç¤ºç»“æœ: {result['status']}")
                print("ğŸ“ æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡.traæ–‡ä»¶ç”Ÿæˆä¸è½¨è¿¹æ± æ›´æ–°")

            if result.get("status") == "failed":
                logger.error(f"ç¬¬{i}æ¬¡PerfAgentè¿­ä»£æ‰§è¡Œå¤±è´¥ï¼Œåœæ­¢åç»­è¿­ä»£")
                break

        logger.info("æ‰€æœ‰PerfAgentè¿­ä»£å‡†å¤‡å®Œæˆ")

        print(f"\nğŸ¯ æ‰§è¡Œæ€»ç»“:")
        print(f"  âœ… è§£æ{len(iterations)}ä¸ªè¿­ä»£é…ç½®")
        print(f"  âœ… æ—¶é—´æˆ³: {timestamp}")
        print(f"  âœ… æ—¥å¿—æ–‡ä»¶: {log_file}")
        print(f"  ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        try:
            final_pool_stats = traj_pool_manager.get_pool_stats()
            print(
                f"  ğŸŠ è½¨è¿¹æ± : {final_pool_stats['total_instances']}å®ä¾‹, {final_pool_stats['total_iterations']}æ€»è¿­ä»£"
            )
            print(f"  ğŸŠ è½¨è¿¹æ± æ–‡ä»¶: {traj_pool_path}")
        except Exception:
            pass

        logger.info("SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œå®Œæˆ")

        logger.info("å¼€å§‹é€‰æ‹©æ¯ä¸ªä»»åŠ¡çš„æœ€ä¼˜è§£")
        try:
            # 1) æ±‡æ€»æ‰€æœ‰è¿­ä»£çš„ preds.json åˆ°è¿è¡Œæ ¹ç›®å½• preds.jsonï¼ˆå« iteration å­—æ®µï¼‰
            root_output_dir = Path(output_dir)
            agg_preds_path = aggregate_all_iterations_preds(root_output_dir, logger)

            # 2) ä»æ±‡æ€» preds.json é‡Œä¸ºæ¯ä¸ªå®ä¾‹é€‰å– runtime æœ€å°çš„è§£ï¼Œç”Ÿæˆ final.json
            if agg_preds_path and Path(agg_preds_path).exists():
                write_final_json_from_preds(Path(agg_preds_path), root_output_dir, logger)
            else:
                logger.warning("æœªæ‰¾åˆ°æ±‡æ€» preds.jsonï¼Œè·³è¿‡ final.json ç”Ÿæˆ")
        except Exception as sel_err:
            logger.warning(f"é€‰æ‹©æœ€ä¼˜è§£å¤±è´¥: {sel_err}")


    except Exception as e:
        if "logger" in locals():
            logger.error(f"è¿è¡Œå‡ºé”™: {e}", exc_info=True)
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

