#!/usr/bin/env python3
"""
è½¨è¿¹æ€»ç»“å™¨
ä¸ºtrajectory poolç”Ÿæˆè½¨è¿¹æ€»ç»“çš„ä¸“ç”¨promptç³»ç»Ÿ
"""

import json
from typing import Any

from core.utils.se_logger import get_se_logger


class TrajSummarizer:
    """è½¨è¿¹æ€»ç»“å™¨ï¼Œç”Ÿæˆè½¨è¿¹åˆ†æpromptå¹¶è§£æå“åº”"""

    def __init__(self):
        self.logger = get_se_logger("traj_summarizer", emoji="ğŸ“Š")

    def get_system_prompt(self) -> str:
        """
        è·å– PerfAgent è½¨è¿¹æ€»ç»“çš„ç³»ç»Ÿæç¤ºè¯

        Returns:
            ç³»ç»Ÿæç¤ºè¯å­—ç¬¦ä¸²
        """
        return """You are an AI assistant specialized in analyzing iterative code optimization trajectories. Your task is to analyze the provided PerfAgent execution data and provide a structured summary of the agent's problem-solving journey.

The agent's guiding principle is "CORRECTNESS FIRST, THEN PERFORMANCE". Your goal is to capture this iterative process, including its successes, failures, and analytical insights.

You will be provided with:
1. A problem description (optional)
2. A trajectory file (.tra) in JSON format containing the agent's step-by-step execution and chat history.
3. A prediction file (.pred) containing the final solution code (this file might be redundant if the trajectory already contains the final code, but should be used as the definitive "final_solution" if present).

Return your analysis in JSON format with the following fields:

- "approach_summary": A concise high-level narrative describing the agent's complete journey and final approach (replaces 'overall_summary').

- "evolution_steps": A list of objects, one for each iteration (i.e., each `assistant` turn) found in the trajectory file. This chronologically tracks the agent's journey.
    - "iteration": The iteration number (e.g., 1, 2, 3...).
    - "thinking_summary": A summary of the agent's reasoning for this step (from its "Thinking" section).
    - "change_type": The *type* of change implemented. (e.g., "initial_implementation", "bugfix", "algorithm", "data-structure", "I/O_optimization", "micro-optimization").
    - "change_description": The specific technique or change implemented.
    - "metrics": The resulting metrics from the *next* 'user' feedback message (i.e., the feedback *after* this change was applied).
    - "status": A concise summary of this iteration's outcome (e.g., "Success: 100% pass rate", "Failed: Correctness regression", "Failed: Error", "Failed: Performance regression").

- "final_solution": {
    - "iteration": The iteration number of the *last* entry in the trajectory.
    - "code": The complete, final code. Use the content from the prediction (.pred) file if provided; otherwise, use the last "Current Program" block from the trajectory.
    - "metrics": The final metrics for this code (from the last user feedback in the trajectory).
    - "status": The final status (e.g., "Correct and Optimized", "Correct but Slow", "Failed Correctness", "Failed (Error)").
}

- "analysis": An object containing high-level insights derived from the entire trajectory.
    - "best_strategy": An object describing the *best correct solution* achieved during the trajectory (if any). If no solution was ever correct, this can be null.
        - "high_level": "Abstract plan (algorithmic viewpoint)."
        - "algorithmic_choices": ["e.g., monotonic stack", "two-pointers"]
        - "data_structures": ["e.g., stack", "heap"]
    - "root_causes_of_failures": A list of objects detailing *why* iterations failed.
        - "iteration": The iteration number that failed.
        - "cause": "The root cause of the failure (e.g., 'Lost nested state by replacing stack with a single variable')."
    - "key_learnings": A list of generalizable insights or patterns observed (e.g., "Agent successfully identified O(n) stack solution but repeatedly broke correctness during I/O micro-optimizations.").
"""

    def get_user_prompt_template(self) -> str:
        """
        è·å–ç”¨æˆ·æç¤ºè¯æ¨¡æ¿

        Returns:
            ç”¨æˆ·æç¤ºè¯æ¨¡æ¿å­—ç¬¦ä¸²
        """
        return """Please analyze the following PerfAgent trajectory and provide insights about the solution approach.

Problem Description:
{problem_description}

Trajectory Data (.tra file):
{trajectory_content}

Prediction Result (.patch/.pred file):
{patch_content}

Please provide your analysis in the JSON format specified in the system prompt."""

    def format_user_prompt(
        self, trajectory_content: str, patch_content: str, problem_description: str | None = None
    ) -> str:
        """
        æ ¼å¼åŒ–ç”¨æˆ·æç¤ºè¯

        Args:
            trajectory_content: è½¨è¿¹æ–‡ä»¶å†…å®¹
            patch_content: é¢„æµ‹æ–‡ä»¶å†…å®¹ (.patch/.pred)
            problem_description: é—®é¢˜æè¿°ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ ¼å¼åŒ–åçš„ç”¨æˆ·æç¤ºè¯
        """
        template = self.get_user_prompt_template()
        return template.format(
            problem_description=problem_description or "N/A",
            trajectory_content=trajectory_content,
            patch_content=patch_content,
        )

    def parse_response(self, response_content: str) -> dict[str, Any]:
        """
        å°†LLMå“åº”å­—ç¬¦ä¸²ä¸¥æ ¼è½¬æ¢ä¸ºJSONå¯¹è±¡ã€‚

        ä»…æ‰§è¡Œå­—ç¬¦ä¸²åˆ°JSONçš„è§£æï¼›è‹¥æ ¼å¼ä¸æ­£ç¡®æˆ–æ— æ³•è§£æï¼ŒæŠ›å‡ºå¼‚å¸¸ã€‚

        Args:
            response_content: LLMå“åº”çš„åŸå§‹å†…å®¹

        Returns:
            è§£æåçš„JSONæ•°æ®

        Raises:
            ValueError: å½“å“åº”ä¸ºç©ºæˆ–æœªæ‰¾åˆ°å¯è§£æçš„JSONç‰‡æ®µæ—¶
            json.JSONDecodeError: å½“JSONè§£æå¤±è´¥æ—¶
        """
        content = (response_content or "").strip()
        if not content:
            raise ValueError("ç©ºå“åº”å†…å®¹ï¼Œæ— æ³•è§£æä¸ºJSON")

        # å°è¯•ç›´æ¥è§£æå®Œæ•´JSON
        if content.startswith("{"):
            return json.loads(content)

        # å°è¯•æå–JSONç‰‡æ®µè¿›è¡Œè§£æ
        start_idx = content.find("{")
        end_idx = content.rfind("}") + 1
        if start_idx >= 0 and end_idx > start_idx:
            json_content = content[start_idx:end_idx]
            return json.loads(json_content)

        # æœªæ‰¾åˆ°å¯è§£æçš„JSONç‰‡æ®µ
        raise ValueError("å“åº”ä¸­æœªæ‰¾åˆ°å¯è§£æçš„JSONå†…å®¹")

    def validate_response_format(self, response_data: dict[str, Any]) -> bool:
        """
        æš‚æ—¶ç¦ç”¨å“åº”æ ¼å¼æ ¡éªŒï¼Œç»Ÿä¸€è¿”å› Trueã€‚
        """
        return True

    def create_fallback_summary(self, trajectory_content: str, patch_content: str, iteration: int) -> dict[str, Any]:
        """
        åˆ›å»ºå¤‡ç”¨æ€»ç»“ï¼ˆå½“LLMè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰

        Args:
            trajectory_content: è½¨è¿¹å†…å®¹
            patch_content: é¢„æµ‹å†…å®¹ (.patch/.pred)
            iteration: è¿­ä»£æ¬¡æ•°

        Returns:
            å¤‡ç”¨æ€»ç»“æ•°æ®
        """
        # ç®€å•çš„å¤‡ç”¨åˆ†æ
        trajectory_length = len(trajectory_content.split("\n")) if trajectory_content else 0
        patch_length = len(patch_content) if patch_content else 0

        return {
            "approach_summary": f"Iteration {iteration} execution with {trajectory_length} trajectory steps",
            "modified_files": ["unknown"],
            "key_changes": "Unable to analyze - LLM summarization failed",
            "strategy": f"iteration_{iteration}_strategy",
            "specific_techniques": ["automated_execution"],
            "tools_used": ["swe_agent"],
            "reasoning_pattern": "step_by_step_execution",
            "assumptions_made": ["standard_swe_agent_assumptions"],
            "components_touched": ["unknown_components"],
            "meta": {
                "is_fallback": True,
                "trajectory_length": trajectory_length,
                "patch_length": patch_length,
                "iteration": iteration,
            },
        }
