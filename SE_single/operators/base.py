#!/usr/bin/env python3

"""
SE Operators Base Classes

åŸºäºAeon generatorsè®¾è®¡ç†å¿µï¼Œä¸ºSEé¡¹ç›®æä¾›æ¨¡å—åŒ–ç®—å­ç³»ç»Ÿã€‚
æ”¯æŒä¸¤ç§åŸºç¡€ç®—å­ç±»å‹ï¼š
- TemplateOperator: è¿”å› initial_code_dirï¼ˆåˆå§‹ä»£ç ç›®å½•ï¼‰
- EnhanceOperator: è¿”å›enhance_history_filter_jsonï¼ˆå†å²å¢å¼ºé…ç½®ï¼‰
"""

import abc
import concurrent.futures
import json
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import yaml
from core.utils.se_logger import get_se_logger

from core.utils.llm_client import LLMClient


class BaseOperator(abc.ABC):
    """SEç®—å­åŸºç±»ï¼Œå®šä¹‰é€šç”¨åŠŸèƒ½å’Œæ¥å£"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–ç®—å­

        Args:
            config: åŒ…å«operator_modelsç­‰é…ç½®ä¿¡æ¯
        """
        self.config = config
        self.model = None  # LLMæ¨¡å‹å®ä¾‹ï¼ˆæ—§è·¯å¾„ï¼‰
        self.llm_client: Optional[LLMClient] = None  # ç»Ÿä¸€çš„ OpenAI LLM å®¢æˆ·ç«¯
        self.logger = get_se_logger(f"operator.{self.get_name()}", emoji="ğŸ”§")

    def _setup_model(self) -> None:
        """è®¾ç½®LLMå®¢æˆ·ç«¯å®ä¾‹ï¼Œæ”¹ç”¨ç»Ÿä¸€çš„ OpenAI æ¥å£å®¢æˆ·ç«¯"""
        if self.llm_client is not None:
            return

        # ä½¿ç”¨ operator_models é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™å›é€€åˆ° model é…ç½®
        model_config_data = self.config.get("operator_models", self.config.get("model", {}))
        # åˆå§‹åŒ–ç»Ÿä¸€ LLM å®¢æˆ·ç«¯
        self.llm_client = LLMClient(model_config_data)
        self.logger.info(f"LLMå®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {model_config_data.get('name')}")

    def _call_llm_api(self, prompt: str, system_prompt: str = "") -> str:
        """
        è°ƒç”¨LLM APIï¼ˆå¤ç”¨Aeon generatorsçš„è°ƒç”¨æ–¹å¼ï¼‰

        Args:
            prompt: ç”¨æˆ·æç¤º
            system_prompt: ç³»ç»Ÿæç¤º

        Returns:
            LLMç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        self._setup_model()

        # æ„å»ºæ¶ˆæ¯å†å²
        history = []
        if system_prompt:
            history.append({"role": "system", "content": system_prompt})
        history.append({"role": "user", "content": prompt})

        try:
            temp = (
                self.config.get("operator_models", self.config.get("model", {})).get("temperature", 0.3)
            )
            max_out = (
                self.config.get("operator_models", self.config.get("model", {})).get("max_output_tokens")
            )
            message = self.llm_client.call_llm(history, temperature=temp, max_tokens=max_out)
            # æŒ‰éœ€è°ƒç”¨ LLMClient çš„æ¸…ç†æ–¹æ³•ï¼Œç§»é™¤ <think> æ ‡ç­¾å†…å®¹
            if message:
                message = self.llm_client.clean_think_tags(message)
            return message if message else ""
        except Exception as e:
            self.logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return ""

    def _extract_code_block_py(self, text: str) -> Optional[str]:
        """
        ä»LLMè¾“å‡ºä¸­æå– ```py \n ... \n ``` ä»£ç å—ï¼Œä»…è¿”å›å—å†…å†…å®¹ã€‚

        è¿”å›:
            æå–åˆ°çš„ä»£ç å­—ç¬¦ä¸²ï¼Œè‹¥æœªæ‰¾åˆ°è¿”å› Noneã€‚
        """
        if not isinstance(text, str) or not text:
            return None
        # æ”¯æŒä¸‰å¼•å·ä¸­å«æœ‰è¯­è¨€æ ‡è®°çš„fenceï¼Œå¦‚```python, ```py
        pattern = re.compile(r"```(?:py|python)\s*\n(.*?)\n```", re.DOTALL | re.IGNORECASE)
        m = pattern.search(text)
        if m:
            code = m.group(1).strip()
            return code if code else None
        return None

    def _extract_code_text(self, text: str) -> Optional[str]:
        """
        ä¼˜å…ˆæå– ```py/```python fenced ä»£ç å—å†…å®¹ï¼›è‹¥æœªæ£€æµ‹åˆ° fenceï¼Œåˆ™è¿”å›çº¯æ–‡æœ¬ã€‚
        è‹¥æ–‡æœ¬é¦–å°¾è¯¯å« fenceï¼ˆä½†æœªåŒ¹é…æˆåŠŸï¼‰ï¼Œå°½åŠ›å‰¥ç¦»é¦–å°¾ fence åè¿”å›ã€‚

        è¿”å›:
            çº¯ä»£ç æ–‡æœ¬ï¼›è‹¥æ— æ³•æå–æˆ–æ–‡æœ¬ä¸ºç©ºï¼Œè¿”å› Noneã€‚
        """
        if not isinstance(text, str) or not text.strip():
            return None
        # å…ˆå°è¯•ä¸¥æ ¼æå– fence ä¸­çš„ä»£ç 
        block = self._extract_code_block_py(text)
        if isinstance(block, str) and block.strip():
            return block.strip()
        # å¦åˆ™æ¥å—çº¯æ–‡æœ¬ä½œä¸ºä»£ç ï¼Œå¹¶å°½åŠ›å‰¥ç¦»é¦–å°¾ fence
        raw_code = text.strip()
        if raw_code.startswith("```") and raw_code.endswith("```"):
            try:
                raw_code = re.sub(r"^```(?:py|python)?\s*\n?", "", raw_code, flags=re.IGNORECASE)
                raw_code = re.sub(r"\n?```$", "", raw_code)
            except Exception:
                pass
        return raw_code if raw_code.strip() else None

    def _require_py_block_with_retry(
        self,
        build_prompt_fn,
        max_retries: int = 2,
        temperature_override: Optional[float] = None,
    ) -> Optional[str]:
        """
        è¦æ±‚LLMä»¥```pyä»£ç å—```è¾“å‡ºï¼Œè‹¥æœªæ»¡è¶³åˆ™é‡è¯•ã€‚

        å‚æ•°:
            build_prompt_fn: å¯è°ƒç”¨ï¼Œè¿”å› (prompt, system_prompt) äºŒå…ƒç»„ï¼›æ¯æ¬¡é‡è¯•å¯æ ¹æ®è®¡æ•°è°ƒæ•´ã€‚
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆä¸å«é¦–è½®ï¼‰ã€‚
            temperature_override: å¯é€‰ï¼Œè¦†ç›–æ¸©åº¦ä½¿æ¨¡å‹æ›´é¡ºä»æ ¼å¼ã€‚

        è¿”å›:
            ä»…ä»£ç å—å†…å®¹çš„å­—ç¬¦ä¸²ï¼›è‹¥å¤±è´¥è¿”å› Noneã€‚
        """
        self._setup_model()

        # ä¿å­˜åŸå§‹æ¸©åº¦é…ç½®ï¼Œå¿…è¦æ—¶ä¸´æ—¶æé«˜/é™ä½
        original_model_cfg = self.config.get("operator_models", self.config.get("model", {}))
        base_temp = original_model_cfg.get("temperature", 0.3)
        temp_to_use = base_temp if temperature_override is None else temperature_override

        for attempt in range(max_retries + 1):
            try:
                prompt, system_prompt = build_prompt_fn(attempt)

                # å¼ºåŒ–æ ¼å¼è¦æ±‚çš„ç³»ç»Ÿæç¤ºè¿½åŠ 
                enforce_tail = "\n\nSTRICT FORMAT: Wrap the entire solution inside a fenced code block starting with ```py and ending with ```."
                allowed_import_scope = (
                    "\n\n### Allowed Imports Scope\n"
                    "You may only import libraries within the scope defined below.\n"
                    "```python\n"
                    "import re\n"
                    "from re import match, search, sub, split, findall, finditer\n"
                    "import sys\n"
                    "from sys import maxsize, stdin\n"
                    "import json\n"
                    "from json import loads\n"
                    "import math\n"
                    "from math import floor, ceil, factorial, sqrt, isqrt, inf, log2, log10, sin, cos, tan, pi, e, comb, perm, gcd, lcm\n"
                    "import copy\n"
                    "import pickle\n"
                    "import heapq\n"
                    "from heapq import heappush, heappop, heapify, heappushpop, nlargest, nsmallest\n"
                    "import bisect\n"
                    "from bisect import bisect_left, bisect_right\n"
                    "import string\n"
                    "from string import ascii_letters, ascii_lowercase, ascii_uppercase, digits, whitespace, punctuation, hexdigits\n"
                    "import random\n"
                    "import operator\n"
                    "import itertools\n"
                    "from itertools import combinations, permutations, product, groupby, chain, accumulate, zip_longest\n"
                    "import functools\n"
                    "from functools import lru_cache, cache, reduce\n"
                    "import collections\n"
                    "from collections import OrderedDict, defaultdict, Counter, deque\n"
                    "from typing import Set, Dict, List, Optional, Tuple\n"
                    "import sortedcontainers # pip install sortedcontainers\n"
                    "from sortedcontainers import SortedList, SortedDict, SortedSet\n"
                    "```\n"
                )

                system_prompt_use = (system_prompt or "") + enforce_tail + allowed_import_scope

                # æ‰‹åŠ¨æ„é€ æ¶ˆæ¯å¹¶è°ƒç”¨åº•å±‚å®¢æˆ·ç«¯ï¼ˆä¿æŒä¸ _call_llm_api ä¸€è‡´ï¼‰
                history = []
                if system_prompt_use:
                    history.append({"role": "system", "content": system_prompt_use})
                history.append({"role": "user", "content": prompt})

                max_out = original_model_cfg.get("max_output_tokens")
                # é¦–æ¬¡å°è¯•ä¿æŒé»˜è®¤ï¼ˆå¯èƒ½ä½¿ç”¨æ€è€ƒæ¨¡å¼ï¼‰ï¼›è‹¥æœªæå–åˆ°ä»£ç å—ï¼Œä¸‹ä¸€æ¬¡å¼ºåˆ¶å…³é—­æ€è€ƒæ¨¡å¼
                enable_thinking = None if attempt == 0 else False # ç›´æ¥å…³é—­æ€è€ƒæ¨¡å¼
                
                self.logger.info(f"ç¬¬{attempt}æ¬¡å°è¯•ï¼Œæ¸©åº¦={temp_to_use}ï¼Œæœ€å¤§è¾“å‡ºtoken={max_out}ï¼Œæ€è€ƒæ¨¡å¼={enable_thinking}")
                self.logger.info(f"è¯·æ±‚å†…å®¹: {prompt}")
                
                message = self.llm_client.call_llm(
                    history,
                    temperature=temp_to_use,
                    max_tokens=max_out,
                    enable_thinking=enable_thinking,
                )
                self.logger.info(f"å“åº”å†…å®¹: {message}")
                if message:
                    message = self.llm_client.clean_think_tags(message)

                code = self._extract_code_block_py(message or "")
                if code:
                    return code

                # è‹¥æœªæå–åˆ°ï¼Œè°ƒæ•´æ¸©åº¦æˆ–åœ¨ä¸‹ä¸€æ¬¡å°è¯•åŠ é‡æ ¼å¼è¯´æ˜
                self.logger.warning("æœªæ£€æµ‹åˆ°```pyä»£ç å—ï¼Œè¿›è¡Œé‡è¯•")
                
            except Exception as e:
                self.logger.error(f"æ ¼å¼åŒ–ä»£ç å—ç”Ÿæˆå¤±è´¥: {e}")
                # ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
                continue

        return None

    def _discover_instances(self, workspace_dir: Path, current_iteration: int) -> List[Dict[str, Any]]:
        """
        å‘ç°å¯å¤„ç†çš„å®ä¾‹åˆ—è¡¨

        Args:
            workspace_dir: å·¥ä½œç›®å½•è·¯å¾„
            current_iteration: å½“å‰è¿­ä»£å·

        Returns:
            å®ä¾‹ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«: {
                'instance_name': str,
                'instance_dir': Path,
                'trajectory_file': Path,
                'previous_iteration': int
                'problem_description': str
            }
        """
        instances = []
        previous_iteration = current_iteration - 1

        if previous_iteration < 1:
            self.logger.warning(f"æ— æ•ˆçš„å‰ä¸€è¿­ä»£å·: {previous_iteration}")
            return instances

        # æŸ¥æ‰¾å‰ä¸€è¿­ä»£çš„è¾“å‡ºç›®å½•
        prev_iter_dir = workspace_dir / f"iteration_{previous_iteration}"
        if not prev_iter_dir.exists():
            self.logger.warning(f"å‰ä¸€è¿­ä»£ç›®å½•ä¸å­˜åœ¨: {prev_iter_dir}")
            return instances

        # æŸ¥æ‰¾å‰ä¸€è¿­ä»£ä¸­çš„æ‰€æœ‰å®ä¾‹ç›®å½•
        for instance_dir in prev_iter_dir.iterdir():
            if not instance_dir.is_dir() or instance_dir.name.startswith("."):
                continue

            # æŸ¥æ‰¾.traè½¨è¿¹æ–‡ä»¶
            tra_files = list(instance_dir.glob("*.tra"))
            if not tra_files:
                continue

            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„.traæ–‡ä»¶
            trajectory_file = tra_files[0]

            # æå–é—®é¢˜é™ˆè¿°ï¼Œé—®é¢˜é™ˆè¿°æ–‡ä»¶åœ¨ instance dir ä¸‹çš„ instance_name.problem
            problem_file = list(instance_dir.glob("*.problem"))[0]
            if not problem_file:
                continue
            with open(problem_file, "r", encoding="utf-8") as f:
                problem_description = f.read().strip()

            instances.append(
                {
                    "instance_name": instance_dir.name,
                    "instance_dir": instance_dir,
                    "trajectory_file": trajectory_file,
                    "previous_iteration": previous_iteration,
                    "problem_description": problem_description,
                }
            )

        self.logger.info(f"å‘ç° {len(instances)} ä¸ªå¯å¤„ç†çš„å®ä¾‹")
        return instances

    def _load_trajectory_data(self, trajectory_file: Path) -> Dict[str, Any]:
        """
        åŠ è½½è½¨è¿¹æ•°æ®ï¼ˆå¤ç”¨Aeon generatorsçš„æ•°æ®åŠ è½½é€»è¾‘ï¼‰

        Args:
            trajectory_file: è½¨è¿¹æ–‡ä»¶è·¯å¾„

        Returns:
            è½¨è¿¹æ•°æ®å­—å…¸
        """
        try:
            with open(trajectory_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"åŠ è½½è½¨è¿¹æ–‡ä»¶å¤±è´¥ {trajectory_file}: {e}")
            return {}

    def _load_traj_pool(self, workspace_dir: Path, instance_name: Optional[str] = None) -> Dict[str, Any]:
        """
        åŠ è½½å·¥ä½œç›®å½•ä¸‹çš„ traj.pool æ–‡ä»¶ã€‚

        å‚æ•°:
            workspace_dir: å·¥ä½œç©ºé—´æ ¹ç›®å½•è·¯å¾„ï¼ˆåŒ…å« iteration_* ç›®å½•çš„ä¸Šå±‚ç›®å½•ï¼‰
            instance_name: è‹¥æä¾›ï¼Œåˆ™è¿”å›è¯¥å®ä¾‹çš„æ± æ•°æ®ï¼›å¦åˆ™è¿”å›æ•´ä¸ªæ± æ•°æ®æ˜ å°„

        è¿”å›:
            - å½“æä¾› instance_name æ—¶ï¼šè¿”å›è¯¥å®ä¾‹çš„å­—å…¸æ•°æ®ï¼ˆæ ¼å¼é€šå¸¸ä¸º {"1": {...}, "2": {...}, ...}ï¼‰
            - æœªæä¾› instance_name æ—¶ï¼šè¿”å› {instance_name: instance_data} çš„å®Œæ•´æ˜ å°„
            - å‘ç”Ÿé”™è¯¯æˆ–æœªæ‰¾åˆ°ï¼šè¿”å› {}
        """
        traj_pool_file = workspace_dir / "traj.pool"

        if not traj_pool_file.exists():
            self.logger.warning(f"traj.poolæ–‡ä»¶ä¸å­˜åœ¨: {traj_pool_file}")
            return {}

        try:
            with open(traj_pool_file, "r", encoding="utf-8") as f:
                pool_data = json.load(f)

            if not isinstance(pool_data, dict):
                self.logger.error(f"traj.pool æ ¼å¼ä¸æ­£ç¡®ï¼ˆæœŸæœ›ä¸ºå­—å…¸ï¼‰: {traj_pool_file}")
                return {}

            if instance_name is None:
                # è¿”å›å®Œæ•´çš„æ± æ•°æ®æ˜ å°„
                return pool_data

            instance_data = pool_data.get(instance_name)
            if isinstance(instance_data, dict):
                return instance_data

            self.logger.warning(f"è½¨è¿¹æ± ä¸­æœªæ‰¾åˆ°å®ä¾‹ {instance_name}")
            return {}

        except Exception as e:
            self.logger.error(f"åŠ è½½traj.poolå¤±è´¥ {traj_pool_file}: {e}")
            return {}

    def _process_single_instance(self, instance_info: Dict[str, Any]) -> Optional[Tuple[str, str]]:
        """
        å¤„ç†å•ä¸ªå®ä¾‹ï¼Œä¼˜å…ˆç”Ÿæˆæ–°çš„åˆå§‹ä»£ç æ–‡æœ¬ï¼›è‹¥ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ä¸Šä¸€è¿­ä»£æäº¤ä»£ç ã€‚

        Args:
            instance_info: å®ä¾‹ä¿¡æ¯å­—å…¸

        Returns:
            (instance_name, initial_code_text) æˆ– None è¡¨ç¤ºå¤„ç†å¤±è´¥
        """
        instance_name = instance_info["instance_name"]
        try:
            # åŠ è½½è½¨è¿¹æ•°æ®ä¸é—®é¢˜é™ˆè¿°
            trajectory_data = self._load_trajectory_data(instance_info["trajectory_file"])
            problem_statement = instance_info.get("problem_description", "")

            # é€šè¿‡å­ç±»é€»è¾‘ç”Ÿæˆæ–°çš„åˆå§‹ä»£ç æ–‡æœ¬ï¼Œå¹¶ç”¨ç»Ÿä¸€æå–åŠ©æ‰‹å¾—åˆ°çº¯ä»£ç 
            generated_code = self._generate_content(instance_info, problem_statement, trajectory_data)
            code_text = self._extract_code_text(generated_code)
            if isinstance(code_text, str) and code_text.strip():
                return (instance_name, code_text)
            # è‹¥å­ç±»æœªæŒ‰è¦æ±‚è¾“å‡ºæˆ–ä¸ºç©ºï¼Œåˆ™é€šè¿‡ç»Ÿä¸€é‡è¯•åŠ©æ‰‹å¼ºåˆ¶è¦æ±‚```py```å°è£…
            def _builder(_attempt: int):
                # å­ç±»é€šå¸¸ä½¿ç”¨å†…éƒ¨æ‹¼æ¥promptï¼›æ­¤å¤„æ— æ³•å¤ç”¨å…¶ç§æœ‰æ–¹æ³•ï¼Œä¿åº•é‡‡ç”¨é—®é¢˜é™ˆè¿°+è½¨è¿¹æ‘˜è¦çŸ­æç¤º
                base_prompt = (
                    "You previously returned content without a proper ```py fenced code block. "
                    "Please regenerate the initial Python solution and wrap it strictly within ```py ... ``` with ONLY Python code.\n\n"
                    f"Problem:\n{problem_statement}\n"
                )
                # å¼•å¯¼ç®€çŸ­ç”Ÿæˆï¼Œé¿å…è¶…é•¿
                system_prompt = (
                    "You are a coding agent. Return ONLY Python code within a fenced block ```py ... ```. "
                    "No prose, no backticks outside the fence."
                )
                return base_prompt, system_prompt

            retry_code = self._require_py_block_with_retry(_builder, max_retries=2)
            if isinstance(retry_code, str) and retry_code.strip():
                return (instance_name, retry_code)

            # ç”Ÿæˆå¤±è´¥åˆ™å›é€€åˆ°ä¸Šä¸€è¿­ä»£æäº¤ä»£ç 
            self.logger.warning(f"{instance_name}: ç”Ÿæˆåˆå§‹ä»£ç å¤±è´¥ï¼Œå°è¯•å›é€€åˆ°ä¸Šä¸€è¿­ä»£æäº¤ä»£ç ")
            fallback_code = self._extract_initial_code(
                instance_info["instance_dir"], instance_name, instance_info["trajectory_file"]
            )
            if isinstance(fallback_code, str) and fallback_code.strip():
                return (instance_name, fallback_code)

            self.logger.warning(f"è·³è¿‡ {instance_name}: æœªèƒ½ç”Ÿæˆæˆ–æå–åˆå§‹ä»£ç ")
            return None

        except Exception as e:
            self.logger.error(f"å¤„ç†å®ä¾‹ {instance_name} æ—¶å‡ºé”™: {e}")
            return None

    @abc.abstractmethod
    def get_name(self) -> str:
        """è·å–ç®—å­åç§°"""
        pass

    @abc.abstractmethod
    def _generate_content(
        self, instance_info: Dict[str, Any], problem_statement: str, trajectory_data: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆå†…å®¹ï¼ˆå­ç±»å®ç°æ ¸å¿ƒé€»è¾‘ï¼‰

        Args:
            instance_info: å®ä¾‹ä¿¡æ¯
            problem_statement: é—®é¢˜é™ˆè¿°
            trajectory_data: è½¨è¿¹æ•°æ®

        Returns:
            ç”Ÿæˆçš„å†…å®¹å­—ç¬¦ä¸²
        """
        pass

    @abc.abstractmethod
    def process(self, workspace_dir: str, current_iteration: int, num_workers: int = 1) -> Optional[Dict[str, str]]:
        """
        å¤„ç†ç®—å­é€»è¾‘çš„ä¸»å…¥å£æ–¹æ³•

        Args:
            workspace_dir: å·¥ä½œç›®å½•è·¯å¾„
            current_iteration: å½“å‰è¿­ä»£å·
            num_workers: å¹¶å‘workeræ•°é‡

        Returns:
            ç®—å­è¿”å›çš„å‚æ•°å­—å…¸ï¼Œå¦‚ {'instance_templates_dir': 'path'} æˆ– Noneè¡¨ç¤ºå¤±è´¥
        """
        pass


class TemplateOperator(BaseOperator):
    """
    æ¨¡æ¿ç®—å­åŸºç±»ï¼Œç”¨äºä¸ºä¸‹ä¸€æ¬¡ PerfAgent è¿è¡Œç”Ÿæˆåˆå§‹ä»£ç ç›®å½•
    è¿”å› initial_code_dir å‚æ•°
    """

    def _create_output_dir(self, workspace_dir: Path, current_iteration: int) -> Path:
        """
        åˆ›å»ºè¾“å‡ºç›®å½•

        Args:
            workspace_dir: å·¥ä½œç›®å½•è·¯å¾„
            current_iteration: å½“å‰è¿­ä»£å·

        Returns:
            è¾“å‡ºç›®å½•è·¯å¾„
        """
        # è¾“å‡ºåˆ°å½“å‰è¿­ä»£çš„åˆå§‹ä»£ç ç›®å½•
        output_dir = workspace_dir / f"iteration_{current_iteration}" / "initial_code"
        output_dir.mkdir(parents=True, exist_ok=True)

        self.logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        return output_dir

    # ä¸å†ç”Ÿæˆ YAML ç³»ç»Ÿæ¨¡æ¿ï¼Œä¿ç•™æ–¹æ³•ä»¥å…¼å®¹æ—§å­ç±»ä½†ä¸ä½¿ç”¨
    def _create_yaml_content(self, strategy_content: str) -> str:
        """
        åˆ›å»ºYAMLæ ¼å¼çš„ç³»ç»Ÿæç¤ºå†…å®¹ï¼ˆå¤ç”¨Aeon generatorsçš„æ ¼å¼ï¼‰

        Args:
            strategy_content: ç­–ç•¥å†…å®¹æ–‡æœ¬

        Returns:
            YAMLæ ¼å¼çš„é…ç½®å†…å®¹
        """
        # åˆ›å»ºYAMLç»“æ„
        yaml_content = {"prompts": {"additional_requirements": strategy_content}}

        return yaml.dump(yaml_content, default_flow_style=False, allow_unicode=True, width=1000)

    # ä¸å†ç”Ÿæˆ YAML ç³»ç»Ÿæ¨¡æ¿ï¼Œä¿ç•™æ–¹æ³•ä»¥å…¼å®¹æ—§å­ç±»ä½†ä¸ä½¿ç”¨
    def _save_instance_template(self, instance_name: str, content: str, output_dir: Path) -> None:
        """
        ä¿å­˜å®ä¾‹æ¨¡æ¿æ–‡ä»¶

        Args:
            instance_name: å®ä¾‹åç§°
            content: ç”Ÿæˆçš„å†…å®¹
            output_dir: è¾“å‡ºç›®å½•
        """
        yaml_content = self._create_yaml_content(content)
        output_file = output_dir / f"{instance_name}.yaml"

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(yaml_content)

        self.logger.debug(f"ä¿å­˜æ¨¡æ¿æ–‡ä»¶: {output_file}")

    def _extract_initial_code(self, instance_dir: Path, instance_name: str, trajectory_file: Path) -> Optional[str]:
        """
        ä»ä¸Šä¸€è¿­ä»£æå–æäº¤ä»£ç ï¼Œä½œä¸ºåˆå§‹ä»£ç ã€‚

        ä¼˜å…ˆè¯»å– <instance_dir>/<instance_name>.predï¼›è‹¥æ— åˆ™ä» .tra JSON çš„ info/metadata.submission ä¸­æå–ã€‚
        """
        try:
            pred_file = instance_dir / f"{instance_name}.pred"
            if pred_file.exists():
                code = pred_file.read_text(encoding="utf-8")
                if isinstance(code, str) and code.strip():
                    return code
        except Exception as e:
            self.logger.warning(f"è¯»å– .pred å¤±è´¥ {pred_file if 'pred_file' in locals() else ''}: {e}")

        try:
            if trajectory_file and trajectory_file.exists():
                with open(trajectory_file, "r", encoding="utf-8") as tf:
                    traj_json = json.load(tf)
                info = traj_json.get("info") or traj_json.get("metadata") or {}
                submission = info.get("submission") or ""
                if isinstance(submission, str) and submission.strip():
                    return submission
        except Exception as e:
            self.logger.warning(f"ä»è½¨è¿¹è¯»å–æäº¤ä»£ç å¤±è´¥ {trajectory_file}: {e}")

        return None

    def _save_initial_code(self, instance_name: str, code_text: str, output_dir: Path) -> Optional[Path]:
        """
        å°†åˆå§‹ä»£ç å†™å…¥è¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨ .py æ‰©å±•åï¼‰ã€‚è¿”å›å†™å…¥æ–‡ä»¶è·¯å¾„æˆ– Noneã€‚
        """
        try:
            if not code_text or not isinstance(code_text, str) or not code_text.strip():
                return None
            output_file = output_dir / f"{instance_name}.py"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(code_text)
            self.logger.debug(f"ä¿å­˜åˆå§‹ä»£ç : {output_file}")
            return output_file
        except Exception as e:
            self.logger.warning(f"å†™å…¥åˆå§‹ä»£ç å¤±è´¥: {e}")
            return None

    @abc.abstractmethod
    def get_strategy_prefix(self) -> str:
        """è·å–ç­–ç•¥å‰ç¼€æ ‡è¯†ï¼ˆå¦‚ 'ALTERNATIVE SOLUTION STRATEGY'ï¼‰"""
        pass

    def process(self, workspace_dir: str, current_iteration: int, num_workers: int = 1) -> Optional[Dict[str, str]]:
        """
        å¤„ç†æ¨¡æ¿ç®—å­é€»è¾‘ï¼ˆä»…ç”Ÿæˆåˆå§‹ä»£ç ç›®å½•ï¼‰

        Args:
            workspace_dir: å·¥ä½œç›®å½•è·¯å¾„
            current_iteration: å½“å‰è¿­ä»£å·
            num_workers: å¹¶å‘workeræ•°é‡

        Returns:
            {'initial_code_dir': 'path'} æˆ– None è¡¨ç¤ºå¤±è´¥
        """
        workspace_path = Path(workspace_dir)

        self.logger.info(f"å¼€å§‹å¤„ç† {self.get_name()} ç®—å­")
        self.logger.info(f"å·¥ä½œç›®å½•: {workspace_path}")
        self.logger.info(f"å½“å‰è¿­ä»£: {current_iteration}")
        self.logger.info(f"å¹¶å‘æ•°: {num_workers}")

        # å‘ç°å®ä¾‹
        instances = self._discover_instances(workspace_path, current_iteration)
        if not instances:
            self.logger.warning("æœªæ‰¾åˆ°å¯å¤„ç†çš„å®ä¾‹")
            return None

        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåˆå§‹ä»£ç ç›®å½•ï¼‰
        output_dir = self._create_output_dir(workspace_path, current_iteration)

        # å¹¶è¡Œå¤„ç†å®ä¾‹
        processed_count = 0
        failed_count = 0

        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_instance = {
                executor.submit(self._process_single_instance, instance_info): instance_info
                for instance_info in instances
            }

            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_instance):
                instance_info = future_to_instance[future]
                instance_name = instance_info["instance_name"]
                try:
                    result = future.result()
                    if result is not None:
                        # è¿”å›å€¼ä¸º (instance_name, initial_code_text)
                        if isinstance(result, tuple) and len(result) >= 2:
                            name, code_text = result[0], result[1]
                            self._save_initial_code(name, code_text, output_dir)
                        else:
                            failed_count += 1
                            self.logger.warning(f"å¤„ç†å®ä¾‹å¤±è´¥: è¿”å›å€¼æ ¼å¼ä¸æ­£ç¡® {result}")
                        processed_count += 1
                        self.logger.debug(f"æˆåŠŸå¤„ç†å®ä¾‹: {instance_name}")
                    else:
                        failed_count += 1
                        self.logger.warning(f"å¤„ç†å®ä¾‹å¤±è´¥: {instance_name}")
                except Exception as e:
                    failed_count += 1
                    self.logger.error(f"å¤„ç†å®ä¾‹ {instance_name} æ—¶å‡ºç°å¼‚å¸¸: {e}")

        self.logger.info(f"å¤„ç†å®Œæˆ: æˆåŠŸ {processed_count}, å¤±è´¥ {failed_count}")

        if processed_count == 0:
            self.logger.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å®ä¾‹")
            return None

        # è¿”å› initial_code_dir å‚æ•°
        try:
            any_code_files = any((output_dir.glob("*.py")))
        except Exception:
            any_code_files = False
        if not any_code_files:
            self.logger.error("æœªç”Ÿæˆä»»ä½•åˆå§‹ä»£ç æ–‡ä»¶")
            return None
        return {"initial_code_dir": str(output_dir)}


class EnhanceOperator(BaseOperator):
    """
    å¢å¼ºç®—å­åŸºç±»ï¼Œç”¨äºç”Ÿæˆå†å²å¢å¼ºé…ç½®
    è¿”å› enhance_history_filter_json å‚æ•°
    """

    def process(self, workspace_dir: str, current_iteration: int, num_workers: int = 1) -> Optional[Dict[str, str]]:
        """
        å¤„ç†å¢å¼ºç®—å­é€»è¾‘ï¼ˆæœªå¼€å‘ï¼‰

        Args:
            workspace_dir: å·¥ä½œç›®å½•è·¯å¾„
            current_iteration: å½“å‰è¿­ä»£å·
            num_workers: å¹¶å‘workeræ•°é‡

        Returns:
            {'enhance_history_filter_json': 'path'} æˆ– Noneè¡¨ç¤ºå¤±è´¥
        """
        # TODO: æ­¤ç±»å‹ç®—å­è¿˜æœªå¼€å‘å®Œæˆ
        self.logger.warning("EnhanceOperator ç±»å‹ç®—å­è¿˜æœªå¼€å‘å®Œæˆ")
        return None
